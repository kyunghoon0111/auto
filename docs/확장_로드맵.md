# í™•ì¥ ë¡œë“œë§µ: ì˜ˆì¸¡ & ìµœì í™” ëª¨ë“ˆ

> ì´ ë¬¸ì„œëŠ” SCM ìš´ì˜ ë¶„ì„ ì‹œìŠ¤í…œì„ ì˜ˆì¸¡/ìµœì í™”ë¡œ í™•ì¥í•  ë•Œ **ê·¸ëŒ€ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì„¤ê³„ì„œ**ì…ë‹ˆë‹¤.
> ê° ëª¨ë“ˆì˜ ì½”ë“œë¥¼ ë³µì‚¬í•˜ì—¬ í•´ë‹¹ íŒŒì¼ì— ë¶™ì—¬ë„£ìœ¼ë©´ ë°”ë¡œ ì‘ë™í•©ë‹ˆë‹¤.
>
> **ê¸°ìˆ  ìŠ¤íƒ**: DuckDB + Polars + Streamlit (Python)
> **ë°ì´í„°ë² ì´ìŠ¤**: `data/scm.duckdb` (ìŠ¤í‚¤ë§ˆ: raw, core, mart, ops)
> **ì„¤ì •**: `config/` ë””ë ‰í„°ë¦¬ YAML íŒŒì¼
> **íŒŒì´í”„ë¼ì¸**: `run.py` 7ë‹¨ê³„ (Ingest â†’ SCM Marts â†’ Allocation â†’ P&L Marts â†’ Reco â†’ Constraints â†’ Coverage)

---

## ì˜ì¡´ì„± DAG (ëª¨ë“ˆ ê°„ ì˜ì¡´ ê´€ê³„)

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ê¸°ì¡´ ì‹œìŠ¤í…œ         â”‚
                    â”‚  core.fact_shipment  â”‚
                    â”‚  core.fact_order     â”‚
                    â”‚  core.fact_po        â”‚
                    â”‚  mart.mart_*         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚              â”‚                   â”‚
            â–¼              â–¼                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ ëª¨ë“ˆ 1    â”‚  â”‚ ëª¨ë“ˆ 3       â”‚   â”‚ ëª¨ë“ˆ 4        â”‚
    â”‚ ìˆ˜ìš” ì˜ˆì¸¡ â”‚  â”‚ ë¦¬ë“œíƒ€ì„ì˜ˆì¸¡ â”‚   â”‚ ê°€ê²© ìµœì í™”   â”‚
    â”‚ (ë…ë¦½)    â”‚  â”‚ (ë…ë¦½)       â”‚   â”‚ (ë…ë¦½)        â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
     â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                  â”‚
     â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ëª¨ë“ˆ 2   â”‚   â”‚ ëª¨ë“ˆ 5       â”‚
â”‚ ë³´ì¶©ë°œì£¼ â”‚   â”‚ ì˜ˆì¸¡ê±°ë²„ë„ŒìŠ¤ â”‚
â”‚ (ëª¨ë“ˆ1â†‘) â”‚   â”‚ (ëª¨ë“ˆ1â†‘)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ì „ì²´ ìš”ì•½ í…Œì´ë¸”

| ëª¨ë“ˆ | ì´ë¦„ | ë‚œì´ë„ | ìƒˆ í…Œì´ë¸” ìˆ˜ | ë³€ê²½/ìƒì„± íŒŒì¼ | ì˜ˆìƒ ì†Œìš” | ì„ í–‰ ëª¨ë“ˆ |
|------|------|--------|-------------|---------------|----------|----------|
| 1 | ìˆ˜ìš” ì˜ˆì¸¡ | ì‰¬ì›€ | 4 (fact 1 + dim 1 + mart 2) | 6ê°œ ìƒì„±, 4ê°œ ìˆ˜ì • | ~1ì£¼ | ì—†ìŒ |
| 2 | ë³´ì¶© ë°œì£¼ | ì‰¬ì›€ | 1 (mart 1) | 2ê°œ ìˆ˜ì • | ~3ì¼ | ëª¨ë“ˆ 1 (ì„ íƒ) |
| 3 | ë¦¬ë“œíƒ€ì„ ì˜ˆì¸¡ | ì‰¬ì›€ | 2 (fact 1 + mart 1) | 4ê°œ ìƒì„±, 3ê°œ ìˆ˜ì • | ~2ì¼ | ì—†ìŒ |
| 4 | ê°€ê²© ìµœì í™” | ë³´í†µ | 2 (fact 1 + mart 1) | 4ê°œ ìƒì„±, 3ê°œ ìˆ˜ì • | ~2ì£¼ | ì—†ìŒ |
| 5 | ì˜ˆì¸¡ ê±°ë²„ë„ŒìŠ¤ | ì‰¬ì›€ | 1 (mart 1) | 2ê°œ ìˆ˜ì • | ~2ì¼ | ëª¨ë“ˆ 1 |

---

## ëª¨ë“ˆ 1: ìˆ˜ìš” ì˜ˆì¸¡ (Demand Forecasting)

### 1.1 ê°œìš”

- **ëª©ì **: ì™¸ë¶€ ì˜ˆì¸¡ ëª¨ë¸(Prophet/ARIMA/XGBoost) ê²°ê³¼ë¥¼ ì ì¬í•˜ê³ , ì‹¤ì  ëŒ€ë¹„ ì •í™•ë„ ì¶”ì 
- **ì…ë ¥**: ì™¸ë¶€ CSV/XLSX â†’ `core.fact_demand_forecast`, ëª¨ë¸ ë©”íƒ€ â†’ `core.dim_forecast_model`
- **ì¶œë ¥**: `mart.mart_forecast_accuracy`, `mart.mart_demand_plan`
- **ì˜ì¡´ì„±**: ê¸°ì¡´ `core.fact_shipment` (ì‹¤ì  ë¹„êµ ëŒ€ìƒ), `mart.mart_open_po` (ë¦¬ë“œíƒ€ì„ ì°¸ì¡°)
- **ë‚œì´ë„**: ì‰¬ì›€ | **ì˜ˆìƒ ì†Œìš”**: ~1ì£¼

**ë°ì´í„° íë¦„**:
```
ì™¸ë¶€ ëª¨ë¸ â†’ CSV(inbox/) â†’ Ingest â†’ core.fact_demand_forecast
                                           â”‚
core.fact_shipment (ì‹¤ì ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
                                   â–¼       â–¼
                          mart.mart_forecast_accuracy
                                   â”‚
                                   â–¼
                          mart.mart_demand_plan
```

### 1.2 DDL (`src/db.py`ì— ì¶”ê°€)

`CORE_FACT_TABLES` ë”•ì…”ë„ˆë¦¬ì— ë‹¤ìŒ ë‘ í•­ëª©ì„ ì¶”ê°€í•©ë‹ˆë‹¤:

```python
# ---------- src/db.py  CORE_FACT_TABLES ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€ ----------

    "core.fact_demand_forecast": """
        CREATE TABLE IF NOT EXISTS core.fact_demand_forecast (
            forecast_id          VARCHAR NOT NULL,
            forecast_date        DATE    NOT NULL,
            target_date          DATE    NOT NULL,
            item_id              VARCHAR NOT NULL,
            warehouse_id         VARCHAR,
            channel_store_id     VARCHAR,
            forecast_qty         DOUBLE  NOT NULL,
            forecast_method      VARCHAR NOT NULL,
            model_version        VARCHAR,
            lower_bound          DOUBLE,
            upper_bound          DOUBLE,
            confidence_level     DOUBLE  DEFAULT 0.95,
            -- ì‹œìŠ¤í…œ ì»¬ëŸ¼
            source_system        VARCHAR,
            load_batch_id        BIGINT,
            source_file_hash     VARCHAR,
            source_pk            VARCHAR,
            loaded_at            TIMESTAMP DEFAULT current_timestamp
        )
    """,

    "core.dim_forecast_model": """
        CREATE TABLE IF NOT EXISTS core.dim_forecast_model (
            model_id             VARCHAR NOT NULL,
            model_name           VARCHAR NOT NULL,
            model_type           VARCHAR NOT NULL,
            parameters_json      VARCHAR,
            trained_at           TIMESTAMP,
            training_data_range  VARCHAR,
            is_active            BOOLEAN DEFAULT true,
            description          VARCHAR,
            -- ì‹œìŠ¤í…œ ì»¬ëŸ¼
            source_system        VARCHAR,
            load_batch_id        BIGINT,
            source_file_hash     VARCHAR,
            source_pk            VARCHAR,
            loaded_at            TIMESTAMP DEFAULT current_timestamp
        )
    """,
```

`MART_TABLES` ë”•ì…”ë„ˆë¦¬ì— ë‹¤ìŒ ë‘ í•­ëª©ì„ ì¶”ê°€í•©ë‹ˆë‹¤:

```python
# ---------- src/db.py  MART_TABLES ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€ ----------

    "mart.mart_forecast_accuracy": """
        CREATE TABLE IF NOT EXISTS mart.mart_forecast_accuracy (
            period               VARCHAR NOT NULL,
            item_id              VARCHAR NOT NULL,
            warehouse_id         VARCHAR,
            forecast_method      VARCHAR NOT NULL,
            actual_qty           DOUBLE,
            forecast_qty         DOUBLE,
            error_qty            DOUBLE,
            abs_error            DOUBLE,
            mape                 DOUBLE,
            bias                 DOUBLE,
            accuracy_pct         DOUBLE
        )
    """,

    "mart.mart_demand_plan": """
        CREATE TABLE IF NOT EXISTS mart.mart_demand_plan (
            item_id              VARCHAR NOT NULL,
            warehouse_id         VARCHAR,
            plan_date            DATE    NOT NULL,
            forecast_30d         DOUBLE,
            forecast_60d         DOUBLE,
            forecast_90d         DOUBLE,
            safety_stock_qty     DOUBLE,
            reorder_point        DOUBLE,
            confidence_level     DOUBLE,
            forecast_method      VARCHAR
        )
    """,
```

### 1.3 ìŠ¤í‚¤ë§ˆ ì„¤ì • (`config/schema.yaml`ì— ì¶”ê°€)

```yaml
# ---------- config/schema.yaml ì— ì¶”ê°€ ----------

fact_demand_forecast:
  description: "ì™¸ë¶€ ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ ê²°ê³¼ (ì˜ˆì¸¡ì¼, ëŒ€ìƒì¼, í’ˆëª©ë³„ ì˜ˆì¸¡ ìˆ˜ëŸ‰)"
  business_key: ["forecast_id"]
  event_date_column: "forecast_date"
  required_columns:
    - {name: "source_system", type: "VARCHAR"}
    - {name: "forecast_id", type: "VARCHAR"}
    - {name: "forecast_date", type: "DATE"}
    - {name: "target_date", type: "DATE"}
    - {name: "item_id", type: "VARCHAR"}
    - {name: "forecast_qty", type: "DOUBLE"}
    - {name: "forecast_method", type: "VARCHAR"}
  optional_columns:
    - {name: "warehouse_id", type: "VARCHAR"}
    - {name: "channel_store_id", type: "VARCHAR"}
    - {name: "model_version", type: "VARCHAR"}
    - {name: "lower_bound", type: "DOUBLE"}
    - {name: "upper_bound", type: "DOUBLE"}
    - {name: "confidence_level", type: "DOUBLE"}

dim_forecast_model:
  description: "ì˜ˆì¸¡ ëª¨ë¸ ë©”íƒ€ë°ì´í„° (ëª¨ë¸ ìœ í˜•, íŒŒë¼ë¯¸í„°, í•™ìŠµ ì •ë³´)"
  business_key: ["model_id"]
  event_date_column: "trained_at"
  required_columns:
    - {name: "source_system", type: "VARCHAR"}
    - {name: "model_id", type: "VARCHAR"}
    - {name: "model_name", type: "VARCHAR"}
    - {name: "model_type", type: "VARCHAR"}
  optional_columns:
    - {name: "parameters_json", type: "VARCHAR"}
    - {name: "trained_at", type: "TIMESTAMP"}
    - {name: "training_data_range", type: "VARCHAR"}
    - {name: "is_active", type: "BOOLEAN"}
    - {name: "description", type: "VARCHAR"}
```

### 1.4 ì˜ˆì¸¡ ì •ì±… ì„¤ì • (`config/policies/forecast_policy.yaml` - ì‹ ê·œ íŒŒì¼)

```yaml
# ---------- config/policies/forecast_policy.yaml (ì‹ ê·œ) ----------
# ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ ì •ì±… ë° í’ˆì§ˆ ì„ê³„ê°’
version: 1

methods:
  NAIVE_AVG:
    description: "ê³¼ê±° Nì¼ ë‹¨ìˆœ í‰ê· "
    lookback_days: 90
    min_data_points: 30
  PROPHET:
    description: "Facebook Prophet ì‹œê³„ì—´ ë¶„í•´"
    lookback_days: 365
    seasonality: true
    changepoint_prior_scale: 0.05
  ARIMA:
    description: "ìë™ ARIMA (auto_arima)"
    lookback_days: 365
    seasonal: true
    m: 7
  XGBOOST:
    description: "XGBoost íšŒê·€ (í”¼ì²˜: lag, dow, month)"
    lookback_days: 180
    features: ["lag_7", "lag_14", "lag_30", "lag_365", "day_of_week", "month", "is_holiday"]

thresholds:
  mape_good: 0.15
  mape_warn: 0.25
  mape_critical: 0.40
  bias_warn: 0.10
  forecast_freshness_days_warn: 7
  forecast_freshness_days_critical: 14
  min_history_days: 30

# ì•ˆì „ì¬ê³  ê³„ì‚° íŒŒë¼ë¯¸í„°
safety_stock:
  service_level: 0.95       # Z = 1.645
  z_score: 1.645
  default_lead_days: 14
  demand_std_lookback_days: 90
```

### 1.5 ë¹Œë” ì½”ë“œ (`src/mart_forecast.py` - ì‹ ê·œ íŒŒì¼)

```python
# ---------- src/mart_forecast.py (ì‹ ê·œ íŒŒì¼) ----------
"""
ìˆ˜ìš” ì˜ˆì¸¡ ë§ˆíŠ¸ ë¹Œë”.
ì™¸ë¶€ ì˜ˆì¸¡ ê²°ê³¼(core.fact_demand_forecast)ì™€ ì‹¤ì (core.fact_shipment)ì„ ê²°í•©í•˜ì—¬
ì •í™•ë„ ë§ˆíŠ¸(mart.mart_forecast_accuracy) ë° ìˆ˜ìš” ê³„íš ë§ˆíŠ¸(mart.mart_demand_plan)ë¥¼ ìƒì„±í•œë‹¤.
"""
import logging
import math
from datetime import date, timedelta

import duckdb
import polars as pl

from src.config import load_config

logger = logging.getLogger(__name__)


# â”€â”€ ìœ í‹¸ë¦¬í‹° (ê¸°ì¡´ íŒ¨í„´ ë™ì¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def _write_mart(con: duckdb.DuckDBPyConnection, df: pl.DataFrame, table: str) -> None:
    """DELETE-INSERT íŒ¨í„´ìœ¼ë¡œ ë§ˆíŠ¸ í…Œì´ë¸”ì— ì ì¬í•œë‹¤."""
    con.execute(f"DELETE FROM {table}")
    if df.height == 0:
        return
    arrow = df.to_arrow()
    staging = f"_stg_{table.replace('.', '_')}"
    con.register(staging, arrow)
    con.execute(f"INSERT INTO {table} SELECT * FROM {staging}")
    con.unregister(staging)


def _safe_query(con: duckdb.DuckDBPyConnection, sql: str) -> pl.DataFrame:
    """ì•ˆì „í•˜ê²Œ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ê³  Polars DataFrameì„ ë°˜í™˜í•œë‹¤."""
    try:
        return con.execute(sql).pl()
    except Exception as e:
        logger.error("Query failed: %s", e)
        return pl.DataFrame()


# â”€â”€ ì •í™•ë„ ë§ˆíŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def build_mart_forecast_accuracy(
    con: duckdb.DuckDBPyConnection, config: dict
) -> pl.DataFrame:
    """
    ì˜ˆì¸¡ vs ì‹¤ì  ì •í™•ë„ë¥¼ ê³„ì‚°í•œë‹¤.
    - ì‹¤ì : core.fact_shipment ì˜ ì¼ë³„/í’ˆëª©ë³„/ì°½ê³ ë³„ ì¶œí•˜ ìˆ˜ëŸ‰ í•©ê³„
    - ì˜ˆì¸¡: core.fact_demand_forecast ì˜ target_date ê¸°ì¤€ ì˜ˆì¸¡ ìˆ˜ëŸ‰
    - ê¸°ê°„(period): target_date ë¥¼ YYYY-MM ìœ¼ë¡œ ì§‘ê³„
    - ì§€í‘œ: error, abs_error, MAPE, bias, accuracy_pct
    """
    sql = """
        WITH actual AS (
            SELECT
                STRFTIME(s.ship_date, '%Y-%m')  AS period,
                s.item_id,
                s.warehouse_id,
                SUM(s.qty_shipped)              AS actual_qty
            FROM core.fact_shipment s
            GROUP BY 1, 2, 3
        ),
        forecast AS (
            SELECT
                STRFTIME(f.target_date, '%Y-%m') AS period,
                f.item_id,
                f.warehouse_id,
                f.forecast_method,
                SUM(f.forecast_qty)              AS forecast_qty
            FROM core.fact_demand_forecast f
            GROUP BY 1, 2, 3, 4
        )
        SELECT
            COALESCE(f.period, a.period)                          AS period,
            COALESCE(f.item_id, a.item_id)                        AS item_id,
            COALESCE(f.warehouse_id, a.warehouse_id)              AS warehouse_id,
            f.forecast_method,
            a.actual_qty,
            f.forecast_qty,
            (f.forecast_qty - a.actual_qty)                       AS error_qty,
            ABS(f.forecast_qty - a.actual_qty)                    AS abs_error,
            CASE
                WHEN a.actual_qty IS NULL OR a.actual_qty = 0 THEN NULL
                ELSE ABS(f.forecast_qty - a.actual_qty) / a.actual_qty
            END                                                   AS mape,
            CASE
                WHEN a.actual_qty IS NULL OR a.actual_qty = 0 THEN NULL
                ELSE (f.forecast_qty - a.actual_qty) / a.actual_qty
            END                                                   AS bias,
            CASE
                WHEN a.actual_qty IS NULL OR a.actual_qty = 0 THEN NULL
                ELSE 1.0 - LEAST(ABS(f.forecast_qty - a.actual_qty) / a.actual_qty, 1.0)
            END                                                   AS accuracy_pct
        FROM forecast f
        FULL OUTER JOIN actual a
            ON  f.period       = a.period
            AND f.item_id      = a.item_id
            AND f.warehouse_id = a.warehouse_id
        WHERE f.forecast_method IS NOT NULL
        ORDER BY period, item_id
    """

    df = _safe_query(con, sql)
    if df.height == 0:
        logger.warning("forecast_accuracy: ì˜ˆì¸¡ ë˜ëŠ” ì‹¤ì  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        _write_mart(con, pl.DataFrame(), "mart.mart_forecast_accuracy")
        return pl.DataFrame()

    # ìŠ¤í‚¤ë§ˆ ì •ë ¬: í…Œì´ë¸” ì»¬ëŸ¼ ìˆœì„œì™€ ì¼ì¹˜ì‹œí‚¨ë‹¤
    result = df.select([
        pl.col("period"),
        pl.col("item_id"),
        pl.col("warehouse_id"),
        pl.col("forecast_method"),
        pl.col("actual_qty"),
        pl.col("forecast_qty"),
        pl.col("error_qty"),
        pl.col("abs_error"),
        pl.col("mape"),
        pl.col("bias"),
        pl.col("accuracy_pct"),
    ])

    _write_mart(con, result, "mart.mart_forecast_accuracy")
    logger.info("mart_forecast_accuracy: %d rows written", result.height)
    return result


# â”€â”€ ìˆ˜ìš” ê³„íš ë§ˆíŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def build_mart_demand_plan(
    con: duckdb.DuckDBPyConnection, config: dict
) -> pl.DataFrame:
    """
    ìˆ˜ìš” ê³„íš ë§ˆíŠ¸ë¥¼ ìƒì„±í•œë‹¤.
    - 30/60/90ì¼ ìˆ˜ìš” ì˜ˆì¸¡ í•©ê³„
    - ì•ˆì „ì¬ê³  = Z * ìˆ˜ìš”í‘œì¤€í¸ì°¨ * sqrt(ë¦¬ë“œíƒ€ì„)
    - ì¬ì£¼ë¬¸ì (ROP) = ë¦¬ë“œíƒ€ì„ ìˆ˜ìš” + ì•ˆì „ì¬ê³ 
    """
    # ì •ì±… ë¡œë“œ: forecast_policy.yaml ì—ì„œ ì•ˆì „ì¬ê³  íŒŒë¼ë¯¸í„° ì½ê¸°
    fc_policy = config.get("forecast_policy", {})
    ss_cfg = fc_policy.get("safety_stock", {})
    z_score = ss_cfg.get("z_score", 1.645)
    default_lead_days = ss_cfg.get("default_lead_days", 14)
    std_lookback = ss_cfg.get("demand_std_lookback_days", 90)

    today = date.today()
    d30 = today + timedelta(days=30)
    d60 = today + timedelta(days=60)
    d90 = today + timedelta(days=90)
    lookback_start = today - timedelta(days=std_lookback)

    # 30/60/90ì¼ ì˜ˆì¸¡ í•©ê³„ (ê°€ì¥ ìµœì‹  forecast_date ì‚¬ìš©)
    forecast_sql = f"""
        WITH latest_fc AS (
            SELECT
                item_id,
                warehouse_id,
                target_date,
                forecast_qty,
                forecast_method,
                confidence_level,
                ROW_NUMBER() OVER (
                    PARTITION BY item_id, warehouse_id, target_date
                    ORDER BY forecast_date DESC
                ) AS rn
            FROM core.fact_demand_forecast
            WHERE target_date >= '{today.isoformat()}'
              AND target_date <= '{d90.isoformat()}'
        )
        SELECT
            item_id,
            warehouse_id,
            forecast_method,
            confidence_level,
            SUM(CASE WHEN target_date <= '{d30.isoformat()}' THEN forecast_qty ELSE 0 END) AS forecast_30d,
            SUM(CASE WHEN target_date <= '{d60.isoformat()}' THEN forecast_qty ELSE 0 END) AS forecast_60d,
            SUM(forecast_qty)                                                                AS forecast_90d
        FROM latest_fc
        WHERE rn = 1
        GROUP BY item_id, warehouse_id, forecast_method, confidence_level
    """

    df_fc = _safe_query(con, forecast_sql)
    if df_fc.height == 0:
        logger.warning("demand_plan: ë¯¸ë˜ ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        _write_mart(con, pl.DataFrame(), "mart.mart_demand_plan")
        return pl.DataFrame()

    # ê³¼ê±° ì‹¤ì  í‘œì¤€í¸ì°¨ (ì¼ë³„ ì¶œí•˜ ê¸°ì¤€)
    std_sql = f"""
        SELECT
            item_id,
            warehouse_id,
            STDDEV_POP(daily_qty) AS demand_std
        FROM (
            SELECT
                item_id,
                warehouse_id,
                ship_date,
                SUM(qty_shipped) AS daily_qty
            FROM core.fact_shipment
            WHERE ship_date >= '{lookback_start.isoformat()}'
            GROUP BY item_id, warehouse_id, ship_date
        ) daily
        GROUP BY item_id, warehouse_id
    """
    df_std = _safe_query(con, std_sql)

    # ë¦¬ë“œíƒ€ì„ (mart_open_po ì—ì„œ í‰ê·  ë¦¬ë“œíƒ€ì„ ì°¸ì¡°, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
    lead_sql = """
        SELECT
            supplier_id,
            AVG(po_lead_days) AS avg_lead_days
        FROM mart.mart_open_po
        GROUP BY supplier_id
    """
    df_lead = _safe_query(con, lead_sql)

    # Polars ê²°í•©: forecast + í‘œì¤€í¸ì°¨
    if df_std.height > 0:
        df_fc = df_fc.join(
            df_std,
            on=["item_id", "warehouse_id"],
            how="left",
        )
    else:
        df_fc = df_fc.with_columns(pl.lit(None).alias("demand_std"))

    # ì•ˆì „ì¬ê³  ë° ROP ê³„ì‚°
    lead_days_val = default_lead_days
    if df_lead.height > 0:
        avg_all = df_lead.select(pl.col("avg_lead_days").mean()).item()
        if avg_all is not None and avg_all > 0:
            lead_days_val = avg_all

    result = df_fc.with_columns([
        pl.lit(today).alias("plan_date"),
        # safety_stock = Z * demand_std * sqrt(lead_days)
        (
            pl.col("demand_std").fill_null(0.0)
            * z_score
            * math.sqrt(lead_days_val)
        ).alias("safety_stock_qty"),
    ]).with_columns([
        # reorder_point = (forecast_30d / 30) * lead_days + safety_stock
        (
            (pl.col("forecast_30d") / 30.0 * lead_days_val)
            + pl.col("safety_stock_qty")
        ).alias("reorder_point"),
    ]).select([
        pl.col("item_id"),
        pl.col("warehouse_id"),
        pl.col("plan_date"),
        pl.col("forecast_30d"),
        pl.col("forecast_60d"),
        pl.col("forecast_90d"),
        pl.col("safety_stock_qty"),
        pl.col("reorder_point"),
        pl.col("confidence_level"),
        pl.col("forecast_method"),
    ])

    _write_mart(con, result, "mart.mart_demand_plan")
    logger.info("mart_demand_plan: %d rows written", result.height)
    return result


# â”€â”€ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def build_all_forecast_marts(
    con: duckdb.DuckDBPyConnection, config: dict
) -> None:
    """ìˆ˜ìš” ì˜ˆì¸¡ ê´€ë ¨ ëª¨ë“  ë§ˆíŠ¸ë¥¼ ë¹Œë“œí•œë‹¤."""
    logger.info("-- ìˆ˜ìš” ì˜ˆì¸¡ ë§ˆíŠ¸ ë¹Œë“œ ì‹œì‘ --")
    build_mart_forecast_accuracy(con, config)
    build_mart_demand_plan(con, config)
    logger.info("-- ìˆ˜ìš” ì˜ˆì¸¡ ë§ˆíŠ¸ ë¹Œë“œ ì™„ë£Œ --")
```

### 1.6 íŒŒì´í”„ë¼ì¸ ì—°ê²° (`run.py` ìˆ˜ì •)

ê¸°ì¡´ `run.py` íŒŒì¼ì— ë‹¤ìŒ ë³€ê²½ì„ ì ìš©í•©ë‹ˆë‹¤.

**1) ì„í¬íŠ¸ ì¶”ê°€** (íŒŒì¼ ìƒë‹¨ ì„í¬íŠ¸ ì˜ì—­):

```python
# ---------- run.py ì„í¬íŠ¸ ì˜ì—­ì— ì¶”ê°€ ----------
from src.mart_forecast import build_all_forecast_marts
```

**2) Phase 2.5 ì¶”ê°€** (Phase 2ì™€ Phase 3 ì‚¬ì´):

```python
# ---------- run.py  run_pipeline() í•¨ìˆ˜ ë‚´ Phase 2 ì´í›„ì— ì¶”ê°€ ----------

        logger.info("=== PHASE 2: SCM Marts ===")
        build_all_scm_marts(con, config)

        # â–¼â–¼â–¼ ì—¬ê¸°ì— ì¶”ê°€ â–¼â–¼â–¼
        logger.info("=== PHASE 2.5: Forecast Marts ===")
        build_all_forecast_marts(con, config)
        # â–²â–²â–² ì¶”ê°€ ë â–²â–²â–²

        logger.info("=== PHASE 3: Cost Allocation ===")
        allocate_all_charges(con, config)
```

> **ì°¸ê³ **: Phase 2.5ë¡œ ì‚½ì…í•˜ëŠ” ì´ìœ ëŠ” ê¸°ì¡´ Phase ë²ˆí˜¸ ì²´ê³„ë¥¼ ìœ ì§€í•˜ë©´ì„œ
> SCM Marts ë¹Œë“œ ì§í›„(ì‹¤ì  ë§ˆíŠ¸ ìƒì„± í›„)ì— ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.
> í–¥í›„ Phase 8 ë“±ìœ¼ë¡œ ì¬ë²ˆí˜¸ë¥¼ ë¶€ì—¬í•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤.

### 1.7 ì»¬ëŸ¼ ë³„ì¹­ (`config/column_aliases.yaml`ì— ì¶”ê°€)

```yaml
# ---------- config/column_aliases.yaml ì— ì¶”ê°€ ----------

fact_demand_forecast:
  forecast_id: "ì˜ˆì¸¡ID"
  forecast_date: "ì˜ˆì¸¡ìƒì„±ì¼"
  target_date: "ì˜ˆì¸¡ëŒ€ìƒì¼"
  item_id: "í’ˆëª©ì½”ë“œ"
  warehouse_id: "ì°½ê³ ì½”ë“œ"
  channel_store_id: "ì±„ë„ë§¤ì¥ì½”ë“œ"
  forecast_qty: "ì˜ˆì¸¡ìˆ˜ëŸ‰"
  forecast_method: "ì˜ˆì¸¡ë°©ë²•"
  model_version: "ëª¨ë¸ë²„ì „"
  lower_bound: "í•˜í•œê°’"
  upper_bound: "ìƒí•œê°’"
  confidence_level: "ì‹ ë¢°ìˆ˜ì¤€"

dim_forecast_model:
  model_id: "ëª¨ë¸ID"
  model_name: "ëª¨ë¸ëª…"
  model_type: "ëª¨ë¸ìœ í˜•"
  parameters_json: "íŒŒë¼ë¯¸í„°(JSON)"
  trained_at: "í•™ìŠµì¼ì‹œ"
  training_data_range: "í•™ìŠµë°ì´í„°ë²”ìœ„"
  is_active: "í™œì„±ì—¬ë¶€"
  description: "ì„¤ëª…"
```

### 1.8 ì»¤ë²„ë¦¬ì§€ ë„ë©”ì¸ (`config/policies/coverage_policy.yaml`ì— ì¶”ê°€)

```yaml
# ---------- config/policies/coverage_policy.yaml  domains ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ ----------

  forecasting:
    label: "ìˆ˜ìš” ì˜ˆì¸¡"
    description: "ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ ê²°ê³¼ ì ì¬ ë° ì •í™•ë„ ì¶”ì "
    source_tables:
      - core.fact_demand_forecast
      - core.dim_forecast_model
    mart_tables:
      - mart.mart_forecast_accuracy
      - mart.mart_demand_plan
    required_freshness_days: 7
    checks:
      - name: "forecast_data_exists"
        sql: "SELECT COUNT(*) FROM core.fact_demand_forecast"
        min_value: 1
      - name: "forecast_accuracy_populated"
        sql: "SELECT COUNT(*) FROM mart.mart_forecast_accuracy"
        min_value: 1
      - name: "forecast_freshness"
        sql: >
          SELECT DATEDIFF('day', MAX(forecast_date), CURRENT_DATE)
          FROM core.fact_demand_forecast
        max_value: 14
      - name: "mape_within_threshold"
        sql: >
          SELECT AVG(mape) FROM mart.mart_forecast_accuracy
          WHERE period = STRFTIME(CURRENT_DATE - INTERVAL '1 month', '%Y-%m')
        max_value: 0.40
```

### 1.9 ëŒ€ì‹œë³´ë“œ (`app/forecast_app.py` - ì‹ ê·œ íŒŒì¼)

```python
# ---------- app/forecast_app.py (ì‹ ê·œ íŒŒì¼) ----------
"""
ìˆ˜ìš” ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ.
ì‹¤í–‰: streamlit run app/forecast_app.py --server.port 8503
"""
import sys
from pathlib import Path

import duckdb
import pandas as pd
import streamlit as st

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.path ì— ì¶”ê°€
ROOT = Path(__file__).parent.parent
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

DB_PATH = ROOT / "data" / "scm.duckdb"

st.set_page_config(page_title="ìˆ˜ìš” ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ", page_icon="ğŸ“Š", layout="wide")


# â”€â”€ ì—°ê²° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


@st.cache_resource
def get_connection():
    """DuckDB ì½ê¸° ì „ìš© ì—°ê²°ì„ ë°˜í™˜í•œë‹¤."""
    return duckdb.connect(str(DB_PATH), read_only=True)


def query_df(con, sql: str) -> pd.DataFrame:
    """ì•ˆì „í•˜ê²Œ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ê³  pandas DataFrame ì„ ë°˜í™˜í•œë‹¤."""
    try:
        return con.execute(sql).fetchdf()
    except Exception:
        return pd.DataFrame()


def _has_table(con, schema: str, table: str) -> bool:
    """ì§€ì •í•œ í…Œì´ë¸”ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•œë‹¤."""
    return (
        con.execute(
            "SELECT COUNT(*) FROM information_schema.tables "
            "WHERE table_schema=? AND table_name=?",
            [schema, table],
        ).fetchone()[0]
        > 0
    )


def _period_filter_widget(con, table: str, key_prefix: str) -> str:
    """ê¸°ê°„ ì„ íƒ ìœ„ì ¯ì„ ë Œë”ë§í•˜ê³  WHERE ì ˆì„ ë°˜í™˜í•œë‹¤."""
    periods = query_df(con, f"SELECT DISTINCT period FROM {table} ORDER BY period DESC")
    if periods is None or len(periods) == 0:
        return ""
    selected = st.selectbox(
        "ê¸°ê°„ ì„ íƒ",
        ["ì „ì²´"] + periods["period"].tolist(),
        key=f"{key_prefix}_period",
    )
    return "" if selected == "ì „ì²´" else f"WHERE period = '{selected}'"


def _item_filter_widget(con, table: str, key_prefix: str) -> str:
    """í’ˆëª© ì„ íƒ ìœ„ì ¯ì„ ë Œë”ë§í•˜ê³  SQL ì¡°ê±´ì„ ë°˜í™˜í•œë‹¤."""
    items = query_df(con, f"SELECT DISTINCT item_id FROM {table} ORDER BY item_id")
    if items is None or len(items) == 0:
        return ""
    selected = st.selectbox(
        "í’ˆëª© ì„ íƒ",
        ["ì „ì²´"] + items["item_id"].tolist(),
        key=f"{key_prefix}_item",
    )
    return "" if selected == "ì „ì²´" else f"item_id = '{selected}'"


# â”€â”€ ë©”ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def main():
    con = get_connection()

    st.title("ğŸ“Š ìˆ˜ìš” ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ")

    # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not _has_table(con, "mart", "mart_forecast_accuracy"):
        st.warning("mart.mart_forecast_accuracy í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return

    tab0, tab1, tab2 = st.tabs(["ì˜ˆì¸¡ vs ì‹¤ì ", "ì •í™•ë„ ì¶”ì´", "ìˆ˜ìš” ê³„íš"])

    # â”€â”€ Tab 0: ì˜ˆì¸¡ vs ì‹¤ì  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with tab0:
        st.subheader("ì˜ˆì¸¡ vs ì‹¤ì  ë¹„êµ")

        col_f1, col_f2 = st.columns(2)
        with col_f1:
            period_where = _period_filter_widget(
                con, "mart.mart_forecast_accuracy", "t0"
            )
        with col_f2:
            item_cond = _item_filter_widget(
                con, "mart.mart_forecast_accuracy", "t0"
            )

        # WHERE ì ˆ ì¡°í•©
        conditions = [c for c in [period_where.replace("WHERE ", ""), item_cond] if c]
        where_clause = ("WHERE " + " AND ".join(conditions)) if conditions else ""

        # KPI ì¹´ë“œ
        kpi_sql = f"""
            SELECT
                ROUND(AVG(mape) * 100, 1)         AS avg_mape_pct,
                ROUND(AVG(bias) * 100, 1)          AS avg_bias_pct,
                ROUND(AVG(accuracy_pct) * 100, 1)  AS avg_accuracy_pct,
                COUNT(*)                            AS row_count
            FROM mart.mart_forecast_accuracy
            {where_clause}
        """
        kpi = query_df(con, kpi_sql)
        if len(kpi) > 0 and kpi.iloc[0]["row_count"] > 0:
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("í‰ê·  MAPE", f"{kpi.iloc[0]['avg_mape_pct']}%")
            c2.metric("í‰ê·  Bias", f"{kpi.iloc[0]['avg_bias_pct']}%")
            c3.metric("í‰ê·  ì •í™•ë„", f"{kpi.iloc[0]['avg_accuracy_pct']}%")
            c4.metric("ë°ì´í„° ê±´ìˆ˜", f"{int(kpi.iloc[0]['row_count']):,}")
        else:
            st.info("ì„ íƒ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # ì°¨íŠ¸: ê¸°ê°„ë³„ ì˜ˆì¸¡ vs ì‹¤ì 
        chart_sql = f"""
            SELECT
                period,
                SUM(actual_qty)   AS actual_qty,
                SUM(forecast_qty) AS forecast_qty
            FROM mart.mart_forecast_accuracy
            {where_clause}
            GROUP BY period
            ORDER BY period
        """
        chart_df = query_df(con, chart_sql)
        if len(chart_df) > 0:
            st.line_chart(
                chart_df.set_index("period")[["actual_qty", "forecast_qty"]],
                use_container_width=True,
            )

        # ì‹ ë¢°êµ¬ê°„ ì°¨íŠ¸ (fact í…Œì´ë¸”ì—ì„œ ì§ì ‘)
        if _has_table(con, "core", "fact_demand_forecast"):
            band_cond = item_cond if item_cond else "1=1"
            band_sql = f"""
                SELECT
                    target_date,
                    SUM(forecast_qty) AS forecast_qty,
                    SUM(lower_bound)  AS lower_bound,
                    SUM(upper_bound)  AS upper_bound
                FROM core.fact_demand_forecast
                WHERE {band_cond}
                GROUP BY target_date
                ORDER BY target_date
            """
            band_df = query_df(con, band_sql)
            if len(band_df) > 0:
                st.subheader("ì˜ˆì¸¡ ì‹ ë¢°êµ¬ê°„")
                st.area_chart(
                    band_df.set_index("target_date")[
                        ["lower_bound", "forecast_qty", "upper_bound"]
                    ],
                    use_container_width=True,
                )

    # â”€â”€ Tab 1: ì •í™•ë„ ì¶”ì´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with tab1:
        st.subheader("ì›”ë³„ MAPE ì¶”ì´")

        trend_sql = """
            SELECT
                period,
                forecast_method,
                ROUND(AVG(mape) * 100, 1) AS avg_mape_pct
            FROM mart.mart_forecast_accuracy
            GROUP BY period, forecast_method
            ORDER BY period
        """
        trend_df = query_df(con, trend_sql)
        if len(trend_df) > 0:
            # í”¼ë²—: ë°©ë²•ë³„ ì»¬ëŸ¼
            pivoted = trend_df.pivot_table(
                index="period",
                columns="forecast_method",
                values="avg_mape_pct",
            )
            st.line_chart(pivoted, use_container_width=True)
        else:
            st.info("ì •í™•ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # ë°©ë²•ë³„ ë¹„êµ ë°” ì°¨íŠ¸
        st.subheader("ì˜ˆì¸¡ ë°©ë²•ë³„ í‰ê·  MAPE ë¹„êµ")
        method_sql = """
            SELECT
                forecast_method,
                ROUND(AVG(mape) * 100, 1) AS avg_mape_pct,
                COUNT(*)                   AS sample_count
            FROM mart.mart_forecast_accuracy
            GROUP BY forecast_method
            ORDER BY avg_mape_pct
        """
        method_df = query_df(con, method_sql)
        if len(method_df) > 0:
            st.bar_chart(
                method_df.set_index("forecast_method")["avg_mape_pct"],
                use_container_width=True,
            )

        # TOP 10 ì •í™•/ë¶€ì •í™• í’ˆëª©
        st.subheader("TOP 10 ì •í™•ë„ ë†’ì€ í’ˆëª©")
        top_sql = """
            SELECT item_id, ROUND(AVG(accuracy_pct) * 100, 1) AS accuracy_pct
            FROM mart.mart_forecast_accuracy
            GROUP BY item_id
            ORDER BY accuracy_pct DESC
            LIMIT 10
        """
        st.dataframe(query_df(con, top_sql), use_container_width=True)

        st.subheader("TOP 10 ì •í™•ë„ ë‚®ì€ í’ˆëª©")
        bottom_sql = """
            SELECT item_id, ROUND(AVG(accuracy_pct) * 100, 1) AS accuracy_pct
            FROM mart.mart_forecast_accuracy
            WHERE accuracy_pct IS NOT NULL
            GROUP BY item_id
            ORDER BY accuracy_pct ASC
            LIMIT 10
        """
        st.dataframe(query_df(con, bottom_sql), use_container_width=True)

    # â”€â”€ Tab 2: ìˆ˜ìš” ê³„íš â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with tab2:
        st.subheader("ìˆ˜ìš” ê³„íš (30/60/90ì¼)")

        if not _has_table(con, "mart", "mart_demand_plan"):
            st.warning("mart.mart_demand_plan í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        # KPI
        plan_kpi_sql = """
            SELECT
                COUNT(DISTINCT item_id) AS item_count,
                ROUND(SUM(forecast_30d), 0) AS total_demand_30d,
                ROUND(SUM(safety_stock_qty), 0) AS total_safety_stock,
                ROUND(AVG(reorder_point), 0) AS avg_reorder_point
            FROM mart.mart_demand_plan
        """
        plan_kpi = query_df(con, plan_kpi_sql)
        if len(plan_kpi) > 0:
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("ëŒ€ìƒ í’ˆëª© ìˆ˜", f"{int(plan_kpi.iloc[0]['item_count']):,}")
            c2.metric("30ì¼ ì´ìˆ˜ìš”", f"{int(plan_kpi.iloc[0]['total_demand_30d']):,}")
            c3.metric("ì´ ì•ˆì „ì¬ê³ ", f"{int(plan_kpi.iloc[0]['total_safety_stock']):,}")
            c4.metric("í‰ê·  ì¬ì£¼ë¬¸ì ", f"{int(plan_kpi.iloc[0]['avg_reorder_point']):,}")

        # ìˆ˜ìš” ê³„íš í…Œì´ë¸”
        plan_sql = """
            SELECT
                item_id                                AS "í’ˆëª©ì½”ë“œ",
                warehouse_id                           AS "ì°½ê³ ì½”ë“œ",
                plan_date                              AS "ê³„íšì¼",
                ROUND(forecast_30d, 0)                 AS "30ì¼ì˜ˆì¸¡",
                ROUND(forecast_60d, 0)                 AS "60ì¼ì˜ˆì¸¡",
                ROUND(forecast_90d, 0)                 AS "90ì¼ì˜ˆì¸¡",
                ROUND(safety_stock_qty, 0)             AS "ì•ˆì „ì¬ê³ ",
                ROUND(reorder_point, 0)                AS "ì¬ì£¼ë¬¸ì ",
                ROUND(confidence_level * 100, 0)       AS "ì‹ ë¢°ìˆ˜ì¤€(%)",
                forecast_method                        AS "ì˜ˆì¸¡ë°©ë²•"
            FROM mart.mart_demand_plan
            ORDER BY forecast_30d DESC
        """
        plan_df = query_df(con, plan_sql)
        if len(plan_df) > 0:
            st.dataframe(plan_df, use_container_width=True, height=500)
        else:
            st.info("ìˆ˜ìš” ê³„íš ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # íˆíŠ¸ë§µ: í’ˆëª©ë³„ ìˆ˜ìš” ë¶„í¬
        st.subheader("í’ˆëª©ë³„ ìˆ˜ìš” íˆíŠ¸ë§µ")
        heatmap_sql = """
            SELECT
                item_id,
                ROUND(forecast_30d, 0) AS "30ì¼",
                ROUND(forecast_60d - forecast_30d, 0) AS "31-60ì¼",
                ROUND(forecast_90d - forecast_60d, 0) AS "61-90ì¼"
            FROM mart.mart_demand_plan
            ORDER BY forecast_90d DESC
            LIMIT 20
        """
        heatmap_df = query_df(con, heatmap_sql)
        if len(heatmap_df) > 0:
            st.bar_chart(
                heatmap_df.set_index("item_id"),
                use_container_width=True,
            )


if __name__ == "__main__":
    main()
```

### 1.10 í…ŒìŠ¤íŠ¸ (`tests/test_forecast.py` - ì‹ ê·œ íŒŒì¼)

```python
# ---------- tests/test_forecast.py (ì‹ ê·œ íŒŒì¼) ----------
"""
ìˆ˜ìš” ì˜ˆì¸¡ ë§ˆíŠ¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸.
ëª¨ë“  í…ŒìŠ¤íŠ¸ëŠ” ì¸ë©”ëª¨ë¦¬ DuckDB ë¥¼ ì‚¬ìš©í•˜ë©° ìì²´ ì™„ê²°ì (self-contained)ì´ë‹¤.
"""
import math
from datetime import date, timedelta

import duckdb
import polars as pl
import pytest


# â”€â”€ í—¬í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def _create_schemas(con):
    """í…ŒìŠ¤íŠ¸ìš© ìŠ¤í‚¤ë§ˆë¥¼ ìƒì„±í•œë‹¤."""
    con.execute("CREATE SCHEMA IF NOT EXISTS core")
    con.execute("CREATE SCHEMA IF NOT EXISTS mart")


def _create_tables(con):
    """í…ŒìŠ¤íŠ¸ì— í•„ìš”í•œ ëª¨ë“  í…Œì´ë¸”ì„ ìƒì„±í•œë‹¤."""
    _create_schemas(con)

    con.execute("""
        CREATE TABLE IF NOT EXISTS core.fact_demand_forecast (
            forecast_id      VARCHAR NOT NULL,
            forecast_date    DATE    NOT NULL,
            target_date      DATE    NOT NULL,
            item_id          VARCHAR NOT NULL,
            warehouse_id     VARCHAR,
            channel_store_id VARCHAR,
            forecast_qty     DOUBLE  NOT NULL,
            forecast_method  VARCHAR NOT NULL,
            model_version    VARCHAR,
            lower_bound      DOUBLE,
            upper_bound      DOUBLE,
            confidence_level DOUBLE DEFAULT 0.95,
            source_system    VARCHAR,
            load_batch_id    BIGINT,
            source_file_hash VARCHAR,
            source_pk        VARCHAR,
            loaded_at        TIMESTAMP DEFAULT current_timestamp
        )
    """)

    con.execute("""
        CREATE TABLE IF NOT EXISTS core.fact_shipment (
            shipment_id      VARCHAR NOT NULL,
            ship_date        DATE    NOT NULL,
            warehouse_id     VARCHAR,
            item_id          VARCHAR NOT NULL,
            qty_shipped      DOUBLE  NOT NULL,
            channel_order_id VARCHAR,
            channel_store_id VARCHAR,
            source_system    VARCHAR,
            load_batch_id    BIGINT,
            source_file_hash VARCHAR,
            source_pk        VARCHAR,
            loaded_at        TIMESTAMP DEFAULT current_timestamp
        )
    """)

    con.execute("""
        CREATE TABLE IF NOT EXISTS mart.mart_forecast_accuracy (
            period          VARCHAR NOT NULL,
            item_id         VARCHAR NOT NULL,
            warehouse_id    VARCHAR,
            forecast_method VARCHAR NOT NULL,
            actual_qty      DOUBLE,
            forecast_qty    DOUBLE,
            error_qty       DOUBLE,
            abs_error       DOUBLE,
            mape            DOUBLE,
            bias            DOUBLE,
            accuracy_pct    DOUBLE
        )
    """)

    con.execute("""
        CREATE TABLE IF NOT EXISTS mart.mart_demand_plan (
            item_id          VARCHAR NOT NULL,
            warehouse_id     VARCHAR,
            plan_date        DATE    NOT NULL,
            forecast_30d     DOUBLE,
            forecast_60d     DOUBLE,
            forecast_90d     DOUBLE,
            safety_stock_qty DOUBLE,
            reorder_point    DOUBLE,
            confidence_level DOUBLE,
            forecast_method  VARCHAR
        )
    """)

    con.execute("""
        CREATE TABLE IF NOT EXISTS mart.mart_open_po (
            po_id              VARCHAR,
            supplier_id        VARCHAR,
            item_id            VARCHAR,
            po_lead_days       DOUBLE,
            eta_vs_actual_days DOUBLE
        )
    """)


def _default_config():
    """ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì„¤ì •ì„ ë°˜í™˜í•œë‹¤."""
    return {
        "forecast_policy": {
            "safety_stock": {
                "z_score": 1.645,
                "default_lead_days": 14,
                "demand_std_lookback_days": 90,
            }
        }
    }


# â”€â”€ ë¹Œë” í•¨ìˆ˜ ì¸ë¼ì¸ (í…ŒìŠ¤íŠ¸ ìì²´ ì™„ê²°ì„± ë³´ì¥) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def _write_mart(con, df, table):
    con.execute(f"DELETE FROM {table}")
    if df.height == 0:
        return
    arrow = df.to_arrow()
    staging = f"_stg_{table.replace('.', '_')}"
    con.register(staging, arrow)
    con.execute(f"INSERT INTO {table} SELECT * FROM {staging}")
    con.unregister(staging)


def _safe_query(con, sql):
    try:
        return con.execute(sql).pl()
    except Exception:
        return pl.DataFrame()


def build_mart_forecast_accuracy(con, config):
    sql = """
        WITH actual AS (
            SELECT
                STRFTIME(s.ship_date, '%Y-%m')  AS period,
                s.item_id,
                s.warehouse_id,
                SUM(s.qty_shipped)              AS actual_qty
            FROM core.fact_shipment s
            GROUP BY 1, 2, 3
        ),
        forecast AS (
            SELECT
                STRFTIME(f.target_date, '%Y-%m') AS period,
                f.item_id,
                f.warehouse_id,
                f.forecast_method,
                SUM(f.forecast_qty)              AS forecast_qty
            FROM core.fact_demand_forecast f
            GROUP BY 1, 2, 3, 4
        )
        SELECT
            COALESCE(f.period, a.period)       AS period,
            COALESCE(f.item_id, a.item_id)     AS item_id,
            COALESCE(f.warehouse_id, a.warehouse_id) AS warehouse_id,
            f.forecast_method,
            a.actual_qty,
            f.forecast_qty,
            (f.forecast_qty - a.actual_qty)    AS error_qty,
            ABS(f.forecast_qty - a.actual_qty) AS abs_error,
            CASE WHEN a.actual_qty IS NULL OR a.actual_qty = 0 THEN NULL
                 ELSE ABS(f.forecast_qty - a.actual_qty) / a.actual_qty END AS mape,
            CASE WHEN a.actual_qty IS NULL OR a.actual_qty = 0 THEN NULL
                 ELSE (f.forecast_qty - a.actual_qty) / a.actual_qty END AS bias,
            CASE WHEN a.actual_qty IS NULL OR a.actual_qty = 0 THEN NULL
                 ELSE 1.0 - LEAST(ABS(f.forecast_qty - a.actual_qty) / a.actual_qty, 1.0) END AS accuracy_pct
        FROM forecast f
        FULL OUTER JOIN actual a
            ON f.period = a.period AND f.item_id = a.item_id AND f.warehouse_id = a.warehouse_id
        WHERE f.forecast_method IS NOT NULL
        ORDER BY period, item_id
    """
    df = _safe_query(con, sql)
    if df.height == 0:
        _write_mart(con, pl.DataFrame(), "mart.mart_forecast_accuracy")
        return pl.DataFrame()
    result = df.select([
        "period", "item_id", "warehouse_id", "forecast_method",
        "actual_qty", "forecast_qty", "error_qty", "abs_error",
        "mape", "bias", "accuracy_pct",
    ])
    _write_mart(con, result, "mart.mart_forecast_accuracy")
    return result


def build_mart_demand_plan(con, config):
    fc_policy = config.get("forecast_policy", {})
    ss_cfg = fc_policy.get("safety_stock", {})
    z_score = ss_cfg.get("z_score", 1.645)
    default_lead_days = ss_cfg.get("default_lead_days", 14)
    std_lookback = ss_cfg.get("demand_std_lookback_days", 90)

    today = date.today()
    d30 = today + timedelta(days=30)
    d60 = today + timedelta(days=60)
    d90 = today + timedelta(days=90)
    lookback_start = today - timedelta(days=std_lookback)

    forecast_sql = f"""
        WITH latest_fc AS (
            SELECT item_id, warehouse_id, target_date, forecast_qty,
                   forecast_method, confidence_level,
                   ROW_NUMBER() OVER (
                       PARTITION BY item_id, warehouse_id, target_date
                       ORDER BY forecast_date DESC
                   ) AS rn
            FROM core.fact_demand_forecast
            WHERE target_date >= '{today.isoformat()}'
              AND target_date <= '{d90.isoformat()}'
        )
        SELECT item_id, warehouse_id, forecast_method, confidence_level,
               SUM(CASE WHEN target_date <= '{d30.isoformat()}' THEN forecast_qty ELSE 0 END) AS forecast_30d,
               SUM(CASE WHEN target_date <= '{d60.isoformat()}' THEN forecast_qty ELSE 0 END) AS forecast_60d,
               SUM(forecast_qty) AS forecast_90d
        FROM latest_fc WHERE rn = 1
        GROUP BY item_id, warehouse_id, forecast_method, confidence_level
    """
    df_fc = _safe_query(con, forecast_sql)
    if df_fc.height == 0:
        _write_mart(con, pl.DataFrame(), "mart.mart_demand_plan")
        return pl.DataFrame()

    std_sql = f"""
        SELECT item_id, warehouse_id, STDDEV_POP(daily_qty) AS demand_std
        FROM (
            SELECT item_id, warehouse_id, ship_date, SUM(qty_shipped) AS daily_qty
            FROM core.fact_shipment WHERE ship_date >= '{lookback_start.isoformat()}'
            GROUP BY item_id, warehouse_id, ship_date
        ) daily GROUP BY item_id, warehouse_id
    """
    df_std = _safe_query(con, std_sql)

    lead_sql = "SELECT supplier_id, AVG(po_lead_days) AS avg_lead_days FROM mart.mart_open_po GROUP BY supplier_id"
    df_lead = _safe_query(con, lead_sql)

    if df_std.height > 0:
        df_fc = df_fc.join(df_std, on=["item_id", "warehouse_id"], how="left")
    else:
        df_fc = df_fc.with_columns(pl.lit(None).alias("demand_std"))

    lead_days_val = default_lead_days
    if df_lead.height > 0:
        avg_all = df_lead.select(pl.col("avg_lead_days").mean()).item()
        if avg_all is not None and avg_all > 0:
            lead_days_val = avg_all

    result = df_fc.with_columns([
        pl.lit(today).alias("plan_date"),
        (pl.col("demand_std").fill_null(0.0) * z_score * math.sqrt(lead_days_val)).alias("safety_stock_qty"),
    ]).with_columns([
        ((pl.col("forecast_30d") / 30.0 * lead_days_val) + pl.col("safety_stock_qty")).alias("reorder_point"),
    ]).select([
        "item_id", "warehouse_id", "plan_date", "forecast_30d", "forecast_60d",
        "forecast_90d", "safety_stock_qty", "reorder_point", "confidence_level",
        "forecast_method",
    ])
    _write_mart(con, result, "mart.mart_demand_plan")
    return result


# â”€â”€ í…ŒìŠ¤íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


class TestForecastAccuracy:
    """mart_forecast_accuracy ë¹Œë” í…ŒìŠ¤íŠ¸."""

    def test_forecast_accuracy_basic(self):
        """ì•Œë ¤ì§„ ì˜ˆì¸¡+ì‹¤ì ì„ ì‚½ì…í•˜ê³ , MAPE ê³„ì‚°ì´ ì˜¬ë°”ë¥¸ì§€ ê²€ì¦í•œë‹¤."""
        con = duckdb.connect(":memory:")
        _create_tables(con)

        # ì‹¤ì : 2024-01 ì— item_A / WH1 ì—ì„œ 100ê°œ ì¶œí•˜
        con.execute("""
            INSERT INTO core.fact_shipment (shipment_id, ship_date, warehouse_id, item_id, qty_shipped)
            VALUES ('S001', '2024-01-15', 'WH1', 'ITEM_A', 100.0)
        """)

        # ì˜ˆì¸¡: ê°™ì€ ê¸°ê°„ 120ê°œ ì˜ˆì¸¡
        con.execute("""
            INSERT INTO core.fact_demand_forecast
                (forecast_id, forecast_date, target_date, item_id, warehouse_id, forecast_qty, forecast_method)
            VALUES ('F001', '2024-01-01', '2024-01-15', 'ITEM_A', 'WH1', 120.0, 'NAIVE_AVG')
        """)

        result = build_mart_forecast_accuracy(con, _default_config())

        assert result.height == 1
        row = result.row(0, named=True)
        assert row["period"] == "2024-01"
        assert row["actual_qty"] == 100.0
        assert row["forecast_qty"] == 120.0
        assert row["error_qty"] == 20.0
        assert row["abs_error"] == 20.0
        # MAPE = |120 - 100| / 100 = 0.2
        assert abs(row["mape"] - 0.2) < 1e-6
        # bias = (120 - 100) / 100 = 0.2
        assert abs(row["bias"] - 0.2) < 1e-6
        # accuracy = 1 - 0.2 = 0.8
        assert abs(row["accuracy_pct"] - 0.8) < 1e-6

        con.close()

    def test_forecast_accuracy_no_data(self):
        """ë°ì´í„°ê°€ ì—†ì„ ë•Œ ë¹ˆ ë§ˆíŠ¸ë¥¼ ìƒì„±í•˜ê³ , ì—ëŸ¬ ì—†ì´ ì¢…ë£Œí•œë‹¤."""
        con = duckdb.connect(":memory:")
        _create_tables(con)

        result = build_mart_forecast_accuracy(con, _default_config())

        assert result.height == 0
        # ë§ˆíŠ¸ í…Œì´ë¸”ë„ ë¹„ì–´ìˆì–´ì•¼ í•¨
        count = con.execute("SELECT COUNT(*) FROM mart.mart_forecast_accuracy").fetchone()[0]
        assert count == 0

        con.close()

    def test_forecast_grain(self):
        """ê°™ì€ í’ˆëª©, ë‹¤ë¥¸ ì°½ê³  â†’ ë³„ë„ í–‰ìœ¼ë¡œ ê³„ì‚°ë˜ëŠ”ì§€ ê²€ì¦í•œë‹¤."""
        con = duckdb.connect(":memory:")
        _create_tables(con)

        # ì‹¤ì : WH1 ì—ì„œ 100ê°œ, WH2 ì—ì„œ 200ê°œ
        con.execute("""
            INSERT INTO core.fact_shipment (shipment_id, ship_date, warehouse_id, item_id, qty_shipped)
            VALUES
                ('S001', '2024-01-15', 'WH1', 'ITEM_A', 100.0),
                ('S002', '2024-01-15', 'WH2', 'ITEM_A', 200.0)
        """)

        # ì˜ˆì¸¡: WH1 ì— 110ê°œ, WH2 ì— 180ê°œ
        con.execute("""
            INSERT INTO core.fact_demand_forecast
                (forecast_id, forecast_date, target_date, item_id, warehouse_id, forecast_qty, forecast_method)
            VALUES
                ('F001', '2024-01-01', '2024-01-15', 'ITEM_A', 'WH1', 110.0, 'PROPHET'),
                ('F002', '2024-01-01', '2024-01-15', 'ITEM_A', 'WH2', 180.0, 'PROPHET')
        """)

        result = build_mart_forecast_accuracy(con, _default_config())

        assert result.height == 2
        wh1 = result.filter(pl.col("warehouse_id") == "WH1")
        wh2 = result.filter(pl.col("warehouse_id") == "WH2")
        assert wh1.height == 1
        assert wh2.height == 1
        # WH1: MAPE = |110-100|/100 = 0.1
        assert abs(wh1.row(0, named=True)["mape"] - 0.1) < 1e-6
        # WH2: MAPE = |180-200|/200 = 0.1
        assert abs(wh2.row(0, named=True)["mape"] - 0.1) < 1e-6

        con.close()

    def test_forecast_method_comparison(self):
        """ë‘ ì˜ˆì¸¡ ë°©ë²•ì— ëŒ€í•´ ì •í™•ë„ê°€ ì˜¬ë°”ë¥´ê²Œ ë¹„êµë˜ëŠ”ì§€ ê²€ì¦í•œë‹¤."""
        con = duckdb.connect(":memory:")
        _create_tables(con)

        # ì‹¤ì : 100ê°œ
        con.execute("""
            INSERT INTO core.fact_shipment (shipment_id, ship_date, warehouse_id, item_id, qty_shipped)
            VALUES ('S001', '2024-01-15', 'WH1', 'ITEM_A', 100.0)
        """)

        # ì˜ˆì¸¡: NAIVE_AVG 130ê°œ (MAPE=0.3), PROPHET 108ê°œ (MAPE=0.08)
        con.execute("""
            INSERT INTO core.fact_demand_forecast
                (forecast_id, forecast_date, target_date, item_id, warehouse_id, forecast_qty, forecast_method)
            VALUES
                ('F001', '2024-01-01', '2024-01-15', 'ITEM_A', 'WH1', 130.0, 'NAIVE_AVG'),
                ('F002', '2024-01-01', '2024-01-15', 'ITEM_A', 'WH1', 108.0, 'PROPHET')
        """)

        result = build_mart_forecast_accuracy(con, _default_config())

        assert result.height == 2
        naive = result.filter(pl.col("forecast_method") == "NAIVE_AVG")
        prophet = result.filter(pl.col("forecast_method") == "PROPHET")
        # PROPHET ì˜ MAPE ê°€ ë” ë‚®ì•„ì•¼ í•¨
        assert prophet.row(0, named=True)["mape"] < naive.row(0, named=True)["mape"]

        con.close()


class TestDemandPlan:
    """mart_demand_plan ë¹Œë” í…ŒìŠ¤íŠ¸."""

    def test_demand_plan_safety_stock(self):
        """ì•ˆì „ì¬ê³  = Z * std * sqrt(lead_days) ë¥¼ ê²€ì¦í•œë‹¤."""
        con = duckdb.connect(":memory:")
        _create_tables(con)

        today = date.today()
        config = _default_config()
        z_score = config["forecast_policy"]["safety_stock"]["z_score"]
        lead_days = config["forecast_policy"]["safety_stock"]["default_lead_days"]

        # ë¯¸ë˜ 30ì¼ ì˜ˆì¸¡ ì‚½ì… (ì¼ë³„ 10ê°œì”©)
        for d in range(1, 31):
            target = today + timedelta(days=d)
            con.execute(f"""
                INSERT INTO core.fact_demand_forecast
                    (forecast_id, forecast_date, target_date, item_id, warehouse_id,
                     forecast_qty, forecast_method, confidence_level)
                VALUES ('F{d:03d}', '{today.isoformat()}', '{target.isoformat()}',
                        'ITEM_A', 'WH1', 10.0, 'PROPHET', 0.95)
            """)

        # ê³¼ê±° ì‹¤ì : ì¼ë³„ ì¶œí•˜ (ë³€ë™ì„ ì£¼ì–´ std > 0 ì´ ë˜ë„ë¡)
        # 8, 10, 12 íŒ¨í„´ â†’ std = sqrt((4+0+4)/3) â‰ˆ 1.633
        for d in range(1, 31):
            past = today - timedelta(days=d)
            qty = [8.0, 10.0, 12.0][d % 3]
            con.execute(f"""
                INSERT INTO core.fact_shipment (shipment_id, ship_date, warehouse_id, item_id, qty_shipped)
                VALUES ('S{d:03d}', '{past.isoformat()}', 'WH1', 'ITEM_A', {qty})
            """)

        result = build_mart_demand_plan(con, config)

        assert result.height >= 1
        row = result.row(0, named=True)

        # ì•ˆì „ì¬ê³  ê²€ì¦
        # ì¼ë³„ ì¶œí•˜: [8,10,12,8,10,12,...] 30ê°œ â†’ í‰ê·  10, ë¶„ì‚° = (2^2*20 + 0*10)/30 â‰ˆ 2.667, std â‰ˆ 1.633
        # safety_stock = 1.645 * std * sqrt(14)
        # ì •í™•í•œ ê°’ì€ ë°ì´í„°ì— ë”°ë¼ ë‹¬ë¼ì§€ë¯€ë¡œ, ì–‘ìˆ˜ì´ê³  í•©ë¦¬ì ì¸ ë²”ìœ„ì¸ì§€ í™•ì¸
        assert row["safety_stock_qty"] > 0
        assert row["reorder_point"] > row["safety_stock_qty"]  # ROP > ì•ˆì „ì¬ê³ 
        assert row["forecast_30d"] == 300.0  # 30ì¼ * 10ê°œ

        con.close()
```

---

## ëª¨ë“ˆ 2: ë³´ì¶© ë°œì£¼ ì œì•ˆ (Replenishment Planning)

### 2.1 ê°œìš”

- **ëª©ì **: í’ˆëª©ë³„ ë°œì£¼ í•„ìš”ëŸ‰/ì‹œê¸°ë¥¼ ìë™ ì œì•ˆ (ì•ˆì „ì¬ê³ , ROP, ì˜ˆì¸¡ ìˆ˜ìš” ê¸°ë°˜)
- **ì…ë ¥**: `mart.mart_demand_plan` (ëª¨ë“ˆ1), `mart.mart_stockout_risk`, `mart.mart_open_po`, `mart.mart_inventory_onhand`
- **ì¶œë ¥**: `mart.mart_replenishment_plan`
- **ì˜ì¡´ì„±**: ëª¨ë“ˆ 1 (ìˆ˜ìš” ì˜ˆì¸¡) -- ì˜ˆì¸¡ ì—†ì´ë„ `mart.mart_stockout_risk`ì˜ ê³¼ê±° í‰ê· ìœ¼ë¡œ ë™ì‘ ê°€ëŠ¥
- **ë‚œì´ë„**: ì‰¬ì›€ | **ì˜ˆìƒ ì†Œìš”**: ~3ì¼

**ë°ì´í„° íë¦„**:
```
mart.mart_demand_plan (ëª¨ë“ˆ1, ì„ íƒì ) â”€â”€â”
mart.mart_stockout_risk â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
mart.mart_inventory_onhand â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â–¶ mart.mart_replenishment_plan
mart.mart_open_po â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
core.fact_po (supplier ë§¤í•‘) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 DDL (`src/db.py`ì— ì¶”ê°€)

```python
# ---------- src/db.py  MART_TABLES ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€ ----------

    "mart.mart_replenishment_plan": """
        CREATE TABLE IF NOT EXISTS mart.mart_replenishment_plan (
            item_id              VARCHAR NOT NULL,
            warehouse_id         VARCHAR NOT NULL,
            supplier_id          VARCHAR,
            current_onhand       DOUBLE,
            safety_stock         DOUBLE,
            reorder_point        DOUBLE,
            forecast_demand_30d  DOUBLE,
            open_po_qty          DOUBLE,
            net_requirement      DOUBLE,
            suggested_order_qty  DOUBLE,
            suggested_order_date DATE,
            supplier_lead_days   DOUBLE,
            priority             VARCHAR,
            as_of_date           DATE    NOT NULL
        )
    """,
```

### 2.3 ë¹Œë” ì½”ë“œ (`src/mart_forecast.py`ì— ì¶”ê°€)

`src/mart_forecast.py` íŒŒì¼ í•˜ë‹¨, `build_all_forecast_marts` í•¨ìˆ˜ ìœ„ì— ë‹¤ìŒ í•¨ìˆ˜ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

```python
# ---------- src/mart_forecast.py ì— í•¨ìˆ˜ ì¶”ê°€ ----------


def build_mart_replenishment_plan(
    con: duckdb.DuckDBPyConnection, config: dict
) -> pl.DataFrame:
    """
    ë³´ì¶© ë°œì£¼ ì œì•ˆ ë§ˆíŠ¸ë¥¼ ìƒì„±í•œë‹¤.
    - ìˆœì†Œìš”ëŸ‰(net_requirement) = ìˆ˜ìš”ì˜ˆì¸¡(30ì¼) - í˜„ì¬ê³  - ì…ê³ ì˜ˆì •(open PO) + ì•ˆì „ì¬ê³ 
    - priority: URGENT(ìˆœì†Œìš” > 0 ì´ê³  ì¬ê³  < ì•ˆì „ì¬ê³ ), NORMAL(ìˆœì†Œìš” > 0), NONE(ì¶©ë¶„)
    - ì˜ˆì¸¡ ë§ˆíŠ¸(mart_demand_plan)ê°€ ì—†ìœ¼ë©´ mart_stockout_risk ì˜ avg_daily_demand ë¡œ ëŒ€ì²´
    """
    thresholds = config.get("thresholds", {}).get("replenishment", {})
    service_z = thresholds.get("safety_stock_service_level", 0.95)
    review_days = thresholds.get("review_cycle_days", 7)
    min_order = thresholds.get("min_order_qty_ea", 100)

    today = date.today()

    # 1) í˜„ì¬ê³ 
    onhand_sql = """
        SELECT item_id, warehouse_id, SUM(onhand_qty) AS current_onhand
        FROM mart.mart_inventory_onhand
        GROUP BY item_id, warehouse_id
    """
    df_onhand = _safe_query(con, onhand_sql)

    # 2) ìˆ˜ìš” ì˜ˆì¸¡ 30ì¼ + ì•ˆì „ì¬ê³  + ROP (ëª¨ë“ˆ1 ë§ˆíŠ¸ ì‚¬ìš© ì‹œë„)
    demand_plan_sql = """
        SELECT item_id, warehouse_id, forecast_30d AS forecast_demand_30d,
               safety_stock_qty AS safety_stock, reorder_point
        FROM mart.mart_demand_plan
    """
    df_demand = _safe_query(con, demand_plan_sql)

    # ëª¨ë“ˆ1 ë§ˆíŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ stockout_risk ì˜ ê³¼ê±° í‰ê· ìœ¼ë¡œ ëŒ€ì²´
    if df_demand.height == 0:
        fallback_sql = """
            SELECT
                item_id, warehouse_id,
                avg_daily_demand * 30                 AS forecast_demand_30d,
                avg_daily_demand * 7 * 1.645          AS safety_stock,
                avg_daily_demand * 14 + avg_daily_demand * 7 * 1.645 AS reorder_point
            FROM mart.mart_stockout_risk
        """
        df_demand = _safe_query(con, fallback_sql)

    if df_demand.height == 0:
        logger.warning("replenishment_plan: ìˆ˜ìš” ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        _write_mart(con, pl.DataFrame(), "mart.mart_replenishment_plan")
        return pl.DataFrame()

    # 3) ì…ê³  ì˜ˆì • (open PO)
    open_po_sql = """
        SELECT
            p.item_id,
            SUM(p.qty_ordered - COALESCE(p.qty_received, 0)) AS open_po_qty,
            AVG(op.po_lead_days)                              AS supplier_lead_days
        FROM core.fact_po p
        LEFT JOIN mart.mart_open_po op ON p.po_id = op.po_id
        GROUP BY p.item_id
    """
    df_po = _safe_query(con, open_po_sql)

    # 4) supplier ë§¤í•‘ (ìµœê·¼ PO ê¸°ì¤€)
    supplier_sql = """
        SELECT item_id, supplier_id,
               ROW_NUMBER() OVER (PARTITION BY item_id ORDER BY po_date DESC) AS rn
        FROM core.fact_po
    """
    df_supplier = _safe_query(con, supplier_sql)
    if df_supplier.height > 0:
        df_supplier = df_supplier.filter(pl.col("rn") == 1).select(["item_id", "supplier_id"])

    # 5) ê²°í•©
    result = df_demand
    if df_onhand.height > 0:
        result = result.join(df_onhand, on=["item_id", "warehouse_id"], how="left")
    else:
        result = result.with_columns(pl.lit(0.0).alias("current_onhand"))

    if df_po.height > 0:
        result = result.join(
            df_po.select(["item_id", "open_po_qty", "supplier_lead_days"]),
            on="item_id",
            how="left",
        )
    else:
        result = result.with_columns([
            pl.lit(0.0).alias("open_po_qty"),
            pl.lit(14.0).alias("supplier_lead_days"),
        ])

    if df_supplier.height > 0:
        result = result.join(df_supplier, on="item_id", how="left")
    else:
        result = result.with_columns(pl.lit(None).cast(pl.Utf8).alias("supplier_id"))

    # 6) ìˆœì†Œìš”ëŸ‰ ë° ìš°ì„ ìˆœìœ„ ê³„ì‚°
    result = result.with_columns([
        pl.col("current_onhand").fill_null(0.0),
        pl.col("open_po_qty").fill_null(0.0),
        pl.col("safety_stock").fill_null(0.0),
        pl.col("supplier_lead_days").fill_null(14.0),
    ]).with_columns([
        # net_requirement = demand_30d + safety_stock - onhand - open_po
        (
            pl.col("forecast_demand_30d")
            + pl.col("safety_stock")
            - pl.col("current_onhand")
            - pl.col("open_po_qty")
        ).alias("net_requirement"),
    ]).with_columns([
        # suggested_order_qty: net_requirement ë¥¼ min_order ë‹¨ìœ„ë¡œ ì˜¬ë¦¼
        pl.when(pl.col("net_requirement") > 0)
          .then(
              ((pl.col("net_requirement") / min_order).ceil() * min_order)
          )
          .otherwise(0.0)
          .alias("suggested_order_qty"),
        # suggested_order_date: ì˜¤ëŠ˜ + review_cycle - supplier_lead_days (ìµœì†Œ ì˜¤ëŠ˜)
        pl.lit(today).alias("suggested_order_date"),
        # priority
        pl.when(
            (pl.col("net_requirement") > 0) & (pl.col("current_onhand") < pl.col("safety_stock"))
        ).then(pl.lit("URGENT"))
          .when(pl.col("net_requirement") > 0)
          .then(pl.lit("NORMAL"))
          .otherwise(pl.lit("NONE"))
          .alias("priority"),
        pl.lit(today).alias("as_of_date"),
    ]).select([
        "item_id", "warehouse_id", "supplier_id", "current_onhand",
        "safety_stock", "reorder_point", "forecast_demand_30d",
        "open_po_qty", "net_requirement", "suggested_order_qty",
        "suggested_order_date", "supplier_lead_days", "priority", "as_of_date",
    ])

    _write_mart(con, result, "mart.mart_replenishment_plan")
    logger.info("mart_replenishment_plan: %d rows written", result.height)
    return result
```

ê·¸ë¦¬ê³  `build_all_forecast_marts` í•¨ìˆ˜ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •í•©ë‹ˆë‹¤:

```python
# ---------- build_all_forecast_marts ìˆ˜ì • ----------

def build_all_forecast_marts(
    con: duckdb.DuckDBPyConnection, config: dict
) -> None:
    """ìˆ˜ìš” ì˜ˆì¸¡ ë° ë³´ì¶© ë°œì£¼ ê´€ë ¨ ëª¨ë“  ë§ˆíŠ¸ë¥¼ ë¹Œë“œí•œë‹¤."""
    logger.info("-- ìˆ˜ìš” ì˜ˆì¸¡ ë§ˆíŠ¸ ë¹Œë“œ ì‹œì‘ --")
    build_mart_forecast_accuracy(con, config)
    build_mart_demand_plan(con, config)
    build_mart_replenishment_plan(con, config)
    logger.info("-- ìˆ˜ìš” ì˜ˆì¸¡ ë§ˆíŠ¸ ë¹Œë“œ ì™„ë£Œ --")
```

### 2.4 ì„ê³„ê°’ ì„¤ì • (`config/thresholds.yaml`ì— ì¶”ê°€)

```yaml
# ---------- config/thresholds.yaml ì— ì¶”ê°€ ----------

replenishment:
  safety_stock_service_level: 0.95   # Z = 1.645
  review_cycle_days: 7               # ë°œì£¼ ê²€í†  ì£¼ê¸°
  min_order_qty_ea: 100              # ìµœì†Œ ë°œì£¼ ìˆ˜ëŸ‰
  max_order_value_krw: 50000000      # ìµœëŒ€ 1íšŒ ë°œì£¼ ê¸ˆì•¡ (5ì²œë§Œì›)
  priority_thresholds:
    urgent_days_cover: 3             # ì¬ê³ ì¼ìˆ˜ 3ì¼ ë¯¸ë§Œ â†’ ê¸´ê¸‰
    normal_days_cover: 7             # ì¬ê³ ì¼ìˆ˜ 7ì¼ ë¯¸ë§Œ â†’ ì¼ë°˜
```

### 2.5 ëŒ€ì‹œë³´ë“œ íƒ­ (`app/scm_app.py`ì— ì¶”ê°€)

ê¸°ì¡´ `app/scm_app.py`ì˜ íƒ­ ëª©ë¡ì— "ë°œì£¼ ì œì•ˆ" íƒ­ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

```python
# ---------- app/scm_app.py  íƒ­ ì •ì˜ ì˜ì—­ì— ì¶”ê°€ ----------
# ê¸°ì¡´ íƒ­ ëª©ë¡ì— "ë°œì£¼ ì œì•ˆ" ì¶”ê°€:
# tab_inv, tab_po, tab_stock, ..., tab_repl = st.tabs([..., "ë°œì£¼ ì œì•ˆ"])

# ---------- ë°œì£¼ ì œì•ˆ íƒ­ ì½”ë“œ ----------

    with tab_repl:
        st.subheader("ë³´ì¶© ë°œì£¼ ì œì•ˆ")

        if not _has_table(con, "mart", "mart_replenishment_plan"):
            st.warning("mart.mart_replenishment_plan í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        else:
            # KPI ì¹´ë“œ
            repl_kpi_sql = """
                SELECT
                    COUNT(*) FILTER (WHERE priority = 'URGENT')  AS urgent_count,
                    COUNT(*) FILTER (WHERE priority = 'NORMAL')  AS normal_count,
                    COUNT(*) FILTER (WHERE priority = 'NONE')    AS none_count,
                    ROUND(SUM(suggested_order_qty), 0)           AS total_order_qty
                FROM mart.mart_replenishment_plan
            """
            repl_kpi = query_df(con, repl_kpi_sql)
            if len(repl_kpi) > 0:
                c1, c2, c3, c4 = st.columns(4)
                c1.metric("ê¸´ê¸‰ ë°œì£¼", f"{int(repl_kpi.iloc[0]['urgent_count']):,}ê±´",
                           delta=None, delta_color="inverse")
                c2.metric("ì¼ë°˜ ë°œì£¼", f"{int(repl_kpi.iloc[0]['normal_count']):,}ê±´")
                c3.metric("ë°œì£¼ ë¶ˆí•„ìš”", f"{int(repl_kpi.iloc[0]['none_count']):,}ê±´")
                c4.metric("ì´ ë°œì£¼ ìˆ˜ëŸ‰", f"{int(repl_kpi.iloc[0]['total_order_qty']):,}")

            # ìš°ì„ ìˆœìœ„ í•„í„°
            priority_filter = st.selectbox(
                "ìš°ì„ ìˆœìœ„ í•„í„°", ["ì „ì²´", "URGENT", "NORMAL", "NONE"], key="repl_priority"
            )
            priority_where = (
                "" if priority_filter == "ì „ì²´"
                else f"WHERE priority = '{priority_filter}'"
            )

            repl_sql = f"""
                SELECT
                    item_id              AS "í’ˆëª©ì½”ë“œ",
                    warehouse_id         AS "ì°½ê³ ì½”ë“œ",
                    supplier_id          AS "ê³µê¸‰ì—…ì²´",
                    ROUND(current_onhand, 0)      AS "í˜„ì¬ê³ ",
                    ROUND(safety_stock, 0)         AS "ì•ˆì „ì¬ê³ ",
                    ROUND(reorder_point, 0)        AS "ì¬ì£¼ë¬¸ì ",
                    ROUND(forecast_demand_30d, 0)  AS "30ì¼ìˆ˜ìš”",
                    ROUND(open_po_qty, 0)          AS "ì…ê³ ì˜ˆì •",
                    ROUND(net_requirement, 0)      AS "ìˆœì†Œìš”ëŸ‰",
                    ROUND(suggested_order_qty, 0)  AS "ë°œì£¼ì œì•ˆìˆ˜ëŸ‰",
                    suggested_order_date           AS "ë°œì£¼ì œì•ˆì¼",
                    ROUND(supplier_lead_days, 0)   AS "ë¦¬ë“œíƒ€ì„(ì¼)",
                    priority                       AS "ìš°ì„ ìˆœìœ„"
                FROM mart.mart_replenishment_plan
                {priority_where}
                ORDER BY
                    CASE priority WHEN 'URGENT' THEN 1 WHEN 'NORMAL' THEN 2 ELSE 3 END,
                    net_requirement DESC
            """
            repl_df = query_df(con, repl_sql)
            if len(repl_df) > 0:
                st.dataframe(repl_df, use_container_width=True, height=500)
            else:
                st.info("ë°œì£¼ ì œì•ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
```

### 2.6 í…ŒìŠ¤íŠ¸ (`tests/test_forecast.py`ì— ì¶”ê°€)

```python
# ---------- tests/test_forecast.py ì— ì¶”ê°€ ----------


def _create_replenishment_tables(con):
    """ë³´ì¶© ë°œì£¼ í…ŒìŠ¤íŠ¸ìš© ì¶”ê°€ í…Œì´ë¸”ì„ ìƒì„±í•œë‹¤."""
    _create_tables(con)

    con.execute("""
        CREATE TABLE IF NOT EXISTS mart.mart_inventory_onhand (
            item_id      VARCHAR,
            warehouse_id VARCHAR,
            onhand_qty   DOUBLE
        )
    """)

    con.execute("""
        CREATE TABLE IF NOT EXISTS mart.mart_stockout_risk (
            item_id          VARCHAR,
            warehouse_id     VARCHAR,
            avg_daily_demand DOUBLE,
            days_of_cover    DOUBLE
        )
    """)

    con.execute("""
        CREATE TABLE IF NOT EXISTS mart.mart_replenishment_plan (
            item_id              VARCHAR NOT NULL,
            warehouse_id         VARCHAR NOT NULL,
            supplier_id          VARCHAR,
            current_onhand       DOUBLE,
            safety_stock         DOUBLE,
            reorder_point        DOUBLE,
            forecast_demand_30d  DOUBLE,
            open_po_qty          DOUBLE,
            net_requirement      DOUBLE,
            suggested_order_qty  DOUBLE,
            suggested_order_date DATE,
            supplier_lead_days   DOUBLE,
            priority             VARCHAR,
            as_of_date           DATE NOT NULL
        )
    """)

    con.execute("""
        CREATE TABLE IF NOT EXISTS core.fact_po (
            po_id        VARCHAR,
            po_date      DATE,
            supplier_id  VARCHAR,
            item_id      VARCHAR,
            eta_date     DATE,
            qty_ordered  DOUBLE,
            qty_received DOUBLE,
            source_system    VARCHAR,
            load_batch_id    BIGINT,
            source_file_hash VARCHAR,
            source_pk        VARCHAR,
            loaded_at        TIMESTAMP DEFAULT current_timestamp
        )
    """)


def build_mart_replenishment_plan_test(con, config):
    """í…ŒìŠ¤íŠ¸ìš© ë³´ì¶© ë°œì£¼ ë¹Œë” (ì¸ë¼ì¸)."""
    thresholds = config.get("thresholds", {}).get("replenishment", {})
    min_order = thresholds.get("min_order_qty_ea", 100)
    today = date.today()

    # ìˆ˜ìš” ê³„íš ë§ˆíŠ¸ì—ì„œ ì½ê¸° ì‹œë„
    df_demand = _safe_query(con, """
        SELECT item_id, warehouse_id, forecast_30d AS forecast_demand_30d,
               safety_stock_qty AS safety_stock, reorder_point
        FROM mart.mart_demand_plan
    """)
    if df_demand.height == 0:
        df_demand = _safe_query(con, """
            SELECT item_id, warehouse_id,
                   avg_daily_demand * 30 AS forecast_demand_30d,
                   avg_daily_demand * 7 * 1.645 AS safety_stock,
                   avg_daily_demand * 14 + avg_daily_demand * 7 * 1.645 AS reorder_point
            FROM mart.mart_stockout_risk
        """)
    if df_demand.height == 0:
        _write_mart(con, pl.DataFrame(), "mart.mart_replenishment_plan")
        return pl.DataFrame()

    df_onhand = _safe_query(con, """
        SELECT item_id, warehouse_id, SUM(onhand_qty) AS current_onhand
        FROM mart.mart_inventory_onhand GROUP BY item_id, warehouse_id
    """)
    df_po = _safe_query(con, """
        SELECT item_id, SUM(qty_ordered - COALESCE(qty_received, 0)) AS open_po_qty,
               14.0 AS supplier_lead_days
        FROM core.fact_po GROUP BY item_id
    """)
    df_supplier = _safe_query(con, """
        SELECT item_id, supplier_id,
               ROW_NUMBER() OVER (PARTITION BY item_id ORDER BY po_date DESC) AS rn
        FROM core.fact_po
    """)
    if df_supplier.height > 0:
        df_supplier = df_supplier.filter(pl.col("rn") == 1).select(["item_id", "supplier_id"])

    result = df_demand
    if df_onhand.height > 0:
        result = result.join(df_onhand, on=["item_id", "warehouse_id"], how="left")
    else:
        result = result.with_columns(pl.lit(0.0).alias("current_onhand"))
    if df_po.height > 0:
        result = result.join(df_po.select(["item_id", "open_po_qty", "supplier_lead_days"]),
                             on="item_id", how="left")
    else:
        result = result.with_columns([
            pl.lit(0.0).alias("open_po_qty"),
            pl.lit(14.0).alias("supplier_lead_days"),
        ])
    if df_supplier.height > 0:
        result = result.join(df_supplier, on="item_id", how="left")
    else:
        result = result.with_columns(pl.lit(None).cast(pl.Utf8).alias("supplier_id"))

    result = result.with_columns([
        pl.col("current_onhand").fill_null(0.0),
        pl.col("open_po_qty").fill_null(0.0),
        pl.col("safety_stock").fill_null(0.0),
        pl.col("supplier_lead_days").fill_null(14.0),
    ]).with_columns([
        (pl.col("forecast_demand_30d") + pl.col("safety_stock")
         - pl.col("current_onhand") - pl.col("open_po_qty")).alias("net_requirement"),
    ]).with_columns([
        pl.when(pl.col("net_requirement") > 0)
          .then(((pl.col("net_requirement") / min_order).ceil() * min_order))
          .otherwise(0.0).alias("suggested_order_qty"),
        pl.lit(today).alias("suggested_order_date"),
        pl.when((pl.col("net_requirement") > 0) & (pl.col("current_onhand") < pl.col("safety_stock")))
          .then(pl.lit("URGENT"))
          .when(pl.col("net_requirement") > 0).then(pl.lit("NORMAL"))
          .otherwise(pl.lit("NONE")).alias("priority"),
        pl.lit(today).alias("as_of_date"),
    ]).select([
        "item_id", "warehouse_id", "supplier_id", "current_onhand",
        "safety_stock", "reorder_point", "forecast_demand_30d",
        "open_po_qty", "net_requirement", "suggested_order_qty",
        "suggested_order_date", "supplier_lead_days", "priority", "as_of_date",
    ])
    _write_mart(con, result, "mart.mart_replenishment_plan")
    return result


class TestReplenishmentPlan:
    """ë³´ì¶© ë°œì£¼ ì œì•ˆ ë§ˆíŠ¸ í…ŒìŠ¤íŠ¸."""

    def test_urgent_when_below_safety_stock(self):
        """í˜„ì¬ê³  < ì•ˆì „ì¬ê³  ì¼ ë•Œ URGENT ìš°ì„ ìˆœìœ„ë¥¼ ê²€ì¦í•œë‹¤."""
        con = duckdb.connect(":memory:")
        _create_replenishment_tables(con)
        config = {
            "thresholds": {"replenishment": {"min_order_qty_ea": 100}},
            "forecast_policy": {"safety_stock": {"z_score": 1.645, "default_lead_days": 14}},
        }

        # stockout_risk (ëª¨ë“ˆ1 ì—†ì´ fallback)
        con.execute("""
            INSERT INTO mart.mart_stockout_risk (item_id, warehouse_id, avg_daily_demand, days_of_cover)
            VALUES ('ITEM_A', 'WH1', 10.0, 3.0)
        """)
        # í˜„ì¬ê³ : 20 (ì•ˆì „ì¬ê³  10*7*1.645â‰ˆ115 ë³´ë‹¤ ë‚®ìŒ)
        con.execute("""
            INSERT INTO mart.mart_inventory_onhand (item_id, warehouse_id, onhand_qty)
            VALUES ('ITEM_A', 'WH1', 20.0)
        """)

        result = build_mart_replenishment_plan_test(con, config)
        assert result.height == 1
        row = result.row(0, named=True)
        assert row["priority"] == "URGENT"
        assert row["suggested_order_qty"] > 0
        con.close()

    def test_none_when_stock_sufficient(self):
        """ì¬ê³ ê°€ ì¶©ë¶„í•  ë•Œ NONE ìš°ì„ ìˆœìœ„ë¥¼ ê²€ì¦í•œë‹¤."""
        con = duckdb.connect(":memory:")
        _create_replenishment_tables(con)
        config = {
            "thresholds": {"replenishment": {"min_order_qty_ea": 100}},
            "forecast_policy": {"safety_stock": {"z_score": 1.645, "default_lead_days": 14}},
        }

        # avg_daily_demand=1 â†’ 30dìˆ˜ìš”=30, safetyâ‰ˆ11.5 â†’ ì´ í•„ìš”â‰ˆ41.5
        con.execute("""
            INSERT INTO mart.mart_stockout_risk (item_id, warehouse_id, avg_daily_demand, days_of_cover)
            VALUES ('ITEM_B', 'WH1', 1.0, 100.0)
        """)
        # í˜„ì¬ê³ : 500 (ì¶©ë¶„)
        con.execute("""
            INSERT INTO mart.mart_inventory_onhand (item_id, warehouse_id, onhand_qty)
            VALUES ('ITEM_B', 'WH1', 500.0)
        """)

        result = build_mart_replenishment_plan_test(con, config)
        assert result.height == 1
        row = result.row(0, named=True)
        assert row["priority"] == "NONE"
        assert row["suggested_order_qty"] == 0.0
        con.close()

    def test_min_order_qty_rounding(self):
        """ë°œì£¼ ìˆ˜ëŸ‰ì´ min_order_qty ë‹¨ìœ„ë¡œ ì˜¬ë¦¼ë˜ëŠ”ì§€ ê²€ì¦í•œë‹¤."""
        con = duckdb.connect(":memory:")
        _create_replenishment_tables(con)
        config = {
            "thresholds": {"replenishment": {"min_order_qty_ea": 50}},
            "forecast_policy": {"safety_stock": {"z_score": 1.645, "default_lead_days": 14}},
        }

        con.execute("""
            INSERT INTO mart.mart_stockout_risk (item_id, warehouse_id, avg_daily_demand, days_of_cover)
            VALUES ('ITEM_C', 'WH1', 5.0, 2.0)
        """)
        con.execute("""
            INSERT INTO mart.mart_inventory_onhand (item_id, warehouse_id, onhand_qty)
            VALUES ('ITEM_C', 'WH1', 10.0)
        """)

        result = build_mart_replenishment_plan_test(con, config)
        assert result.height == 1
        row = result.row(0, named=True)
        # ë°œì£¼ ìˆ˜ëŸ‰ì€ 50ì˜ ë°°ìˆ˜ì—¬ì•¼ í•¨
        assert row["suggested_order_qty"] > 0
        assert row["suggested_order_qty"] % 50 == 0
        con.close()
```

---

## ëª¨ë“ˆ 3: ë¦¬ë“œíƒ€ì„ ì˜ˆì¸¡ (Lead Time Prediction)

### 3.1 ê°œìš”

- **ëª©ì **: ê³µê¸‰ì—…ì²´ë³„/ê²½ë¡œë³„ ë¦¬ë“œíƒ€ì„ì„ ì˜ˆì¸¡í•˜ì—¬ ë°œì£¼ ì‹œê¸° ì •í™•ë„ í–¥ìƒ
- **ì…ë ¥**: `core.fact_po` + `mart.mart_open_po` (ì‹¤ì ), ì™¸ë¶€ ì˜ˆì¸¡ CSV â†’ `core.fact_lead_time_forecast`
- **ì¶œë ¥**: `mart.mart_lead_time_analysis`
- **ì˜ì¡´ì„±**: ì—†ìŒ (ë…ë¦½)
- **ë‚œì´ë„**: ì‰¬ì›€ | **ì˜ˆìƒ ì†Œìš”**: ~2ì¼

**ë°ì´í„° íë¦„**:
```
ì™¸ë¶€ ëª¨ë¸ â†’ CSV(inbox/) â†’ Ingest â†’ core.fact_lead_time_forecast
                                             â”‚
mart.mart_open_po (ì‹¤ì  ë¦¬ë“œíƒ€ì„) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
core.fact_po (PO ì •ë³´) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚
                                             â–¼
                                 mart.mart_lead_time_analysis
```

### 3.2 DDL (`src/db.py`ì— ì¶”ê°€)

```python
# ---------- src/db.py  CORE_FACT_TABLES ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€ ----------

    "core.fact_lead_time_forecast": """
        CREATE TABLE IF NOT EXISTS core.fact_lead_time_forecast (
            forecast_id          VARCHAR NOT NULL,
            forecast_date        DATE    NOT NULL,
            supplier_id          VARCHAR NOT NULL,
            item_id              VARCHAR,
            origin_country       VARCHAR,
            dest_warehouse_id    VARCHAR,
            predicted_lead_days  DOUBLE  NOT NULL,
            lower_bound_days     DOUBLE,
            upper_bound_days     DOUBLE,
            confidence_level     DOUBLE  DEFAULT 0.95,
            forecast_method      VARCHAR NOT NULL,
            -- ì‹œìŠ¤í…œ ì»¬ëŸ¼
            source_system        VARCHAR,
            load_batch_id        BIGINT,
            source_file_hash     VARCHAR,
            source_pk            VARCHAR,
            loaded_at            TIMESTAMP DEFAULT current_timestamp
        )
    """,
```

```python
# ---------- src/db.py  MART_TABLES ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€ ----------

    "mart.mart_lead_time_analysis": """
        CREATE TABLE IF NOT EXISTS mart.mart_lead_time_analysis (
            period               VARCHAR NOT NULL,
            supplier_id          VARCHAR NOT NULL,
            item_id              VARCHAR,
            avg_actual_lead_days DOUBLE,
            avg_predicted_lead_days DOUBLE,
            lead_time_error_days DOUBLE,
            lead_time_abs_error  DOUBLE,
            lead_time_mape       DOUBLE,
            sample_count         INTEGER,
            p90_actual_lead_days DOUBLE,
            on_time_rate         DOUBLE,
            late_delivery_count  INTEGER
        )
    """,
```

### 3.3 ìŠ¤í‚¤ë§ˆ ì„¤ì • (`config/schema.yaml`ì— ì¶”ê°€)

```yaml
# ---------- config/schema.yaml ì— ì¶”ê°€ ----------

fact_lead_time_forecast:
  description: "ê³µê¸‰ì—…ì²´ë³„ ë¦¬ë“œíƒ€ì„ ì˜ˆì¸¡ ëª¨ë¸ ê²°ê³¼"
  business_key: ["forecast_id"]
  event_date_column: "forecast_date"
  required_columns:
    - {name: "source_system", type: "VARCHAR"}
    - {name: "forecast_id", type: "VARCHAR"}
    - {name: "forecast_date", type: "DATE"}
    - {name: "supplier_id", type: "VARCHAR"}
    - {name: "predicted_lead_days", type: "DOUBLE"}
    - {name: "forecast_method", type: "VARCHAR"}
  optional_columns:
    - {name: "item_id", type: "VARCHAR"}
    - {name: "origin_country", type: "VARCHAR"}
    - {name: "dest_warehouse_id", type: "VARCHAR"}
    - {name: "lower_bound_days", type: "DOUBLE"}
    - {name: "upper_bound_days", type: "DOUBLE"}
    - {name: "confidence_level", type: "DOUBLE"}
```

### 3.4 ë¹Œë” ì½”ë“œ (`src/mart_lead_time.py` - ì‹ ê·œ íŒŒì¼)

```python
# ---------- src/mart_lead_time.py (ì‹ ê·œ íŒŒì¼) ----------
"""
ë¦¬ë“œíƒ€ì„ ë¶„ì„ ë§ˆíŠ¸ ë¹Œë”.
ê³µê¸‰ì—…ì²´ë³„ ì‹¤ì  ë¦¬ë“œíƒ€ì„ê³¼ ì˜ˆì¸¡ ë¦¬ë“œíƒ€ì„ì„ ë¹„êµí•˜ì—¬ ì •í™•ë„ ë° ë‚©ê¸° ì¤€ìˆ˜ìœ¨ì„ ë¶„ì„í•œë‹¤.
"""
import logging

import duckdb
import polars as pl

logger = logging.getLogger(__name__)


def _write_mart(con: duckdb.DuckDBPyConnection, df: pl.DataFrame, table: str) -> None:
    """DELETE-INSERT íŒ¨í„´ìœ¼ë¡œ ë§ˆíŠ¸ í…Œì´ë¸”ì— ì ì¬í•œë‹¤."""
    con.execute(f"DELETE FROM {table}")
    if df.height == 0:
        return
    arrow = df.to_arrow()
    staging = f"_stg_{table.replace('.', '_')}"
    con.register(staging, arrow)
    con.execute(f"INSERT INTO {table} SELECT * FROM {staging}")
    con.unregister(staging)


def _safe_query(con: duckdb.DuckDBPyConnection, sql: str) -> pl.DataFrame:
    """ì•ˆì „í•˜ê²Œ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ê³  Polars DataFrameì„ ë°˜í™˜í•œë‹¤."""
    try:
        return con.execute(sql).pl()
    except Exception as e:
        logger.error("Query failed: %s", e)
        return pl.DataFrame()


def build_mart_lead_time_analysis(
    con: duckdb.DuckDBPyConnection, config: dict
) -> pl.DataFrame:
    """
    ë¦¬ë“œíƒ€ì„ ë¶„ì„ ë§ˆíŠ¸ë¥¼ ìƒì„±í•œë‹¤.
    - ì‹¤ì : mart.mart_open_po ì˜ po_lead_days (ì‹¤ì œ ë¦¬ë“œíƒ€ì„)
    - ì˜ˆì¸¡: core.fact_lead_time_forecast ì˜ predicted_lead_days
    - ì§€í‘œ: í‰ê·  ì˜¤ì°¨, MAPE, ë‚©ê¸° ì¤€ìˆ˜ìœ¨(on_time_rate), P90 ë¦¬ë“œíƒ€ì„
    """
    # ì„ê³„ê°’: ì§€ì—° ê¸°ì¤€ (ê¸°ë³¸ 2ì¼ ì´ˆê³¼ ì‹œ ì§€ì—°ìœ¼ë¡œ íŒë‹¨)
    thresholds = config.get("thresholds", {}).get("constraints", {}).get("supply", {})
    late_threshold_days = thresholds.get("late_threshold_days", 2)

    sql = f"""
        WITH actual_lt AS (
            -- ì‹¤ì  ë¦¬ë“œíƒ€ì„: PO ê¸°ì¤€
            SELECT
                STRFTIME(p.po_date, '%Y-%m')  AS period,
                p.supplier_id,
                p.item_id,
                op.po_lead_days               AS actual_lead_days,
                op.eta_vs_actual_days
            FROM core.fact_po p
            JOIN mart.mart_open_po op ON p.po_id = op.po_id
            WHERE op.po_lead_days IS NOT NULL
        ),
        predicted_lt AS (
            -- ì˜ˆì¸¡ ë¦¬ë“œíƒ€ì„
            SELECT
                STRFTIME(f.forecast_date, '%Y-%m') AS period,
                f.supplier_id,
                f.item_id,
                f.predicted_lead_days
            FROM core.fact_lead_time_forecast f
        ),
        combined AS (
            SELECT
                COALESCE(a.period, p.period)           AS period,
                COALESCE(a.supplier_id, p.supplier_id) AS supplier_id,
                COALESCE(a.item_id, p.item_id)         AS item_id,
                a.actual_lead_days,
                p.predicted_lead_days,
                a.eta_vs_actual_days
            FROM actual_lt a
            FULL OUTER JOIN predicted_lt p
                ON  a.period       = p.period
                AND a.supplier_id  = p.supplier_id
                AND a.item_id      = p.item_id
        )
        SELECT
            period,
            supplier_id,
            item_id,
            ROUND(AVG(actual_lead_days), 1)                          AS avg_actual_lead_days,
            ROUND(AVG(predicted_lead_days), 1)                       AS avg_predicted_lead_days,
            ROUND(AVG(predicted_lead_days - actual_lead_days), 1)    AS lead_time_error_days,
            ROUND(AVG(ABS(predicted_lead_days - actual_lead_days)), 1) AS lead_time_abs_error,
            CASE
                WHEN AVG(actual_lead_days) = 0 OR AVG(actual_lead_days) IS NULL THEN NULL
                ELSE ROUND(AVG(ABS(predicted_lead_days - actual_lead_days))
                     / AVG(actual_lead_days), 4)
            END                                                      AS lead_time_mape,
            COUNT(*)::INTEGER                                        AS sample_count,
            ROUND(PERCENTILE_CONT(0.9) WITHIN GROUP (ORDER BY actual_lead_days), 1) AS p90_actual_lead_days,
            ROUND(
                SUM(CASE WHEN eta_vs_actual_days <= {late_threshold_days} THEN 1 ELSE 0 END)::DOUBLE
                / NULLIF(COUNT(*), 0), 4
            )                                                        AS on_time_rate,
            SUM(CASE WHEN eta_vs_actual_days > {late_threshold_days} THEN 1 ELSE 0 END)::INTEGER AS late_delivery_count
        FROM combined
        WHERE period IS NOT NULL AND supplier_id IS NOT NULL
        GROUP BY period, supplier_id, item_id
        ORDER BY period, supplier_id
    """

    df = _safe_query(con, sql)
    if df.height == 0:
        logger.warning("lead_time_analysis: ë¦¬ë“œíƒ€ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        _write_mart(con, pl.DataFrame(), "mart.mart_lead_time_analysis")
        return pl.DataFrame()

    result = df.select([
        "period", "supplier_id", "item_id",
        "avg_actual_lead_days", "avg_predicted_lead_days",
        "lead_time_error_days", "lead_time_abs_error", "lead_time_mape",
        "sample_count", "p90_actual_lead_days", "on_time_rate", "late_delivery_count",
    ])

    _write_mart(con, result, "mart.mart_lead_time_analysis")
    logger.info("mart_lead_time_analysis: %d rows written", result.height)
    return result


def build_all_lead_time_marts(
    con: duckdb.DuckDBPyConnection, config: dict
) -> None:
    """ë¦¬ë“œíƒ€ì„ ê´€ë ¨ ëª¨ë“  ë§ˆíŠ¸ë¥¼ ë¹Œë“œí•œë‹¤."""
    logger.info("-- ë¦¬ë“œíƒ€ì„ ë§ˆíŠ¸ ë¹Œë“œ ì‹œì‘ --")
    build_mart_lead_time_analysis(con, config)
    logger.info("-- ë¦¬ë“œíƒ€ì„ ë§ˆíŠ¸ ë¹Œë“œ ì™„ë£Œ --")
```

### 3.5 íŒŒì´í”„ë¼ì¸ ì—°ê²° (`run.py` ìˆ˜ì •)

```python
# ---------- run.py ì„í¬íŠ¸ ì˜ì—­ì— ì¶”ê°€ ----------
from src.mart_lead_time import build_all_lead_time_marts
```

```python
# ---------- run.py  run_pipeline() í•¨ìˆ˜ ë‚´ Phase 2.5 ì´í›„ì— ì¶”ê°€ ----------

        logger.info("=== PHASE 2.5: Forecast Marts ===")
        build_all_forecast_marts(con, config)

        # â–¼â–¼â–¼ ì—¬ê¸°ì— ì¶”ê°€ â–¼â–¼â–¼
        logger.info("=== PHASE 2.6: Lead Time Marts ===")
        build_all_lead_time_marts(con, config)
        # â–²â–²â–² ì¶”ê°€ ë â–²â–²â–²

        logger.info("=== PHASE 3: Cost Allocation ===")
```

### 3.6 ëŒ€ì‹œë³´ë“œ ê°•í™” (`app/scm_app.py` ì…ê³ /ë°œì£¼ íƒ­ì— ì¶”ê°€)

ê¸°ì¡´ SCM ëŒ€ì‹œë³´ë“œì˜ ì…ê³ /ë°œì£¼ íƒ­ì— ì˜ˆì¸¡ vs ì‹¤ì  ë¦¬ë“œíƒ€ì„ ë¹„êµ ì„¹ì…˜ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

```python
# ---------- app/scm_app.py  ì…ê³ /ë°œì£¼ íƒ­ (tab_po) í•˜ë‹¨ì— ì¶”ê°€ ----------

        # â”€â”€ ë¦¬ë“œíƒ€ì„ ì˜ˆì¸¡ vs ì‹¤ì  ë¹„êµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if _has_table(con, "mart", "mart_lead_time_analysis"):
            st.divider()
            st.subheader("ë¦¬ë“œíƒ€ì„ ì˜ˆì¸¡ vs ì‹¤ì ")

            lt_kpi_sql = """
                SELECT
                    ROUND(AVG(avg_actual_lead_days), 1)  AS avg_actual,
                    ROUND(AVG(avg_predicted_lead_days), 1) AS avg_predicted,
                    ROUND(AVG(on_time_rate) * 100, 1)    AS avg_on_time_pct,
                    SUM(late_delivery_count)              AS total_late
                FROM mart.mart_lead_time_analysis
            """
            lt_kpi = query_df(con, lt_kpi_sql)
            if len(lt_kpi) > 0:
                c1, c2, c3, c4 = st.columns(4)
                c1.metric("í‰ê·  ì‹¤ì  ë¦¬ë“œíƒ€ì„", f"{lt_kpi.iloc[0]['avg_actual']}ì¼")
                c2.metric("í‰ê·  ì˜ˆì¸¡ ë¦¬ë“œíƒ€ì„", f"{lt_kpi.iloc[0]['avg_predicted']}ì¼")
                c3.metric("ë‚©ê¸° ì¤€ìˆ˜ìœ¨", f"{lt_kpi.iloc[0]['avg_on_time_pct']}%")
                c4.metric("ì§€ì—° ê±´ìˆ˜", f"{int(lt_kpi.iloc[0]['total_late']):,}ê±´")

            # ê³µê¸‰ì—…ì²´ë³„ ë¦¬ë“œíƒ€ì„ ë¹„êµ ì°¨íŠ¸
            lt_chart_sql = """
                SELECT
                    supplier_id AS "ê³µê¸‰ì—…ì²´",
                    ROUND(AVG(avg_actual_lead_days), 1) AS "ì‹¤ì (ì¼)",
                    ROUND(AVG(avg_predicted_lead_days), 1) AS "ì˜ˆì¸¡(ì¼)"
                FROM mart.mart_lead_time_analysis
                GROUP BY supplier_id
                ORDER BY AVG(avg_actual_lead_days) DESC
                LIMIT 15
            """
            lt_chart = query_df(con, lt_chart_sql)
            if len(lt_chart) > 0:
                st.bar_chart(
                    lt_chart.set_index("ê³µê¸‰ì—…ì²´"),
                    use_container_width=True,
                )

            # ì›”ë³„ ë‚©ê¸° ì¤€ìˆ˜ìœ¨ ì¶”ì´
            lt_trend_sql = """
                SELECT
                    period AS "ê¸°ê°„",
                    ROUND(AVG(on_time_rate) * 100, 1) AS "ë‚©ê¸°ì¤€ìˆ˜ìœ¨(%)"
                FROM mart.mart_lead_time_analysis
                GROUP BY period
                ORDER BY period
            """
            lt_trend = query_df(con, lt_trend_sql)
            if len(lt_trend) > 0:
                st.subheader("ì›”ë³„ ë‚©ê¸° ì¤€ìˆ˜ìœ¨ ì¶”ì´")
                st.line_chart(
                    lt_trend.set_index("ê¸°ê°„"),
                    use_container_width=True,
                )
```

### 3.7 í…ŒìŠ¤íŠ¸ (`tests/test_lead_time.py` - ì‹ ê·œ íŒŒì¼)

```python
# ---------- tests/test_lead_time.py (ì‹ ê·œ íŒŒì¼) ----------
"""
ë¦¬ë“œíƒ€ì„ ë¶„ì„ ë§ˆíŠ¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸.
"""
from datetime import date

import duckdb
import polars as pl
import pytest


def _write_mart(con, df, table):
    con.execute(f"DELETE FROM {table}")
    if df.height == 0:
        return
    arrow = df.to_arrow()
    staging = f"_stg_{table.replace('.', '_')}"
    con.register(staging, arrow)
    con.execute(f"INSERT INTO {table} SELECT * FROM {staging}")
    con.unregister(staging)


def _safe_query(con, sql):
    try:
        return con.execute(sql).pl()
    except Exception:
        return pl.DataFrame()


def _create_lt_tables(con):
    """ë¦¬ë“œíƒ€ì„ í…ŒìŠ¤íŠ¸ìš© í…Œì´ë¸” ìƒì„±."""
    con.execute("CREATE SCHEMA IF NOT EXISTS core")
    con.execute("CREATE SCHEMA IF NOT EXISTS mart")

    con.execute("""
        CREATE TABLE IF NOT EXISTS core.fact_po (
            po_id VARCHAR, po_date DATE, supplier_id VARCHAR, item_id VARCHAR,
            eta_date DATE, qty_ordered DOUBLE, qty_received DOUBLE,
            source_system VARCHAR, load_batch_id BIGINT,
            source_file_hash VARCHAR, source_pk VARCHAR,
            loaded_at TIMESTAMP DEFAULT current_timestamp
        )
    """)
    con.execute("""
        CREATE TABLE IF NOT EXISTS mart.mart_open_po (
            po_id VARCHAR, supplier_id VARCHAR, item_id VARCHAR,
            po_lead_days DOUBLE, eta_vs_actual_days DOUBLE
        )
    """)
    con.execute("""
        CREATE TABLE IF NOT EXISTS core.fact_lead_time_forecast (
            forecast_id VARCHAR NOT NULL, forecast_date DATE NOT NULL,
            supplier_id VARCHAR NOT NULL, item_id VARCHAR,
            origin_country VARCHAR, dest_warehouse_id VARCHAR,
            predicted_lead_days DOUBLE NOT NULL,
            lower_bound_days DOUBLE, upper_bound_days DOUBLE,
            confidence_level DOUBLE DEFAULT 0.95,
            forecast_method VARCHAR NOT NULL,
            source_system VARCHAR, load_batch_id BIGINT,
            source_file_hash VARCHAR, source_pk VARCHAR,
            loaded_at TIMESTAMP DEFAULT current_timestamp
        )
    """)
    con.execute("""
        CREATE TABLE IF NOT EXISTS mart.mart_lead_time_analysis (
            period VARCHAR NOT NULL, supplier_id VARCHAR NOT NULL,
            item_id VARCHAR, avg_actual_lead_days DOUBLE,
            avg_predicted_lead_days DOUBLE, lead_time_error_days DOUBLE,
            lead_time_abs_error DOUBLE, lead_time_mape DOUBLE,
            sample_count INTEGER, p90_actual_lead_days DOUBLE,
            on_time_rate DOUBLE, late_delivery_count INTEGER
        )
    """)


def build_mart_lead_time_analysis_test(con, config):
    """í…ŒìŠ¤íŠ¸ìš© ì¸ë¼ì¸ ë¹Œë”."""
    thresholds = config.get("thresholds", {}).get("constraints", {}).get("supply", {})
    late_threshold_days = thresholds.get("late_threshold_days", 2)

    sql = f"""
        WITH actual_lt AS (
            SELECT STRFTIME(p.po_date, '%Y-%m') AS period, p.supplier_id, p.item_id,
                   op.po_lead_days AS actual_lead_days, op.eta_vs_actual_days
            FROM core.fact_po p
            JOIN mart.mart_open_po op ON p.po_id = op.po_id
            WHERE op.po_lead_days IS NOT NULL
        ),
        predicted_lt AS (
            SELECT STRFTIME(f.forecast_date, '%Y-%m') AS period, f.supplier_id,
                   f.item_id, f.predicted_lead_days
            FROM core.fact_lead_time_forecast f
        ),
        combined AS (
            SELECT COALESCE(a.period, p.period) AS period,
                   COALESCE(a.supplier_id, p.supplier_id) AS supplier_id,
                   COALESCE(a.item_id, p.item_id) AS item_id,
                   a.actual_lead_days, p.predicted_lead_days, a.eta_vs_actual_days
            FROM actual_lt a
            FULL OUTER JOIN predicted_lt p
                ON a.period = p.period AND a.supplier_id = p.supplier_id AND a.item_id = p.item_id
        )
        SELECT period, supplier_id, item_id,
               ROUND(AVG(actual_lead_days), 1) AS avg_actual_lead_days,
               ROUND(AVG(predicted_lead_days), 1) AS avg_predicted_lead_days,
               ROUND(AVG(predicted_lead_days - actual_lead_days), 1) AS lead_time_error_days,
               ROUND(AVG(ABS(predicted_lead_days - actual_lead_days)), 1) AS lead_time_abs_error,
               CASE WHEN AVG(actual_lead_days) = 0 OR AVG(actual_lead_days) IS NULL THEN NULL
                    ELSE ROUND(AVG(ABS(predicted_lead_days - actual_lead_days)) / AVG(actual_lead_days), 4) END AS lead_time_mape,
               COUNT(*)::INTEGER AS sample_count,
               ROUND(PERCENTILE_CONT(0.9) WITHIN GROUP (ORDER BY actual_lead_days), 1) AS p90_actual_lead_days,
               ROUND(SUM(CASE WHEN eta_vs_actual_days <= {late_threshold_days} THEN 1 ELSE 0 END)::DOUBLE
                     / NULLIF(COUNT(*), 0), 4) AS on_time_rate,
               SUM(CASE WHEN eta_vs_actual_days > {late_threshold_days} THEN 1 ELSE 0 END)::INTEGER AS late_delivery_count
        FROM combined
        WHERE period IS NOT NULL AND supplier_id IS NOT NULL
        GROUP BY period, supplier_id, item_id
        ORDER BY period, supplier_id
    """
    df = _safe_query(con, sql)
    if df.height == 0:
        _write_mart(con, pl.DataFrame(), "mart.mart_lead_time_analysis")
        return pl.DataFrame()
    result = df.select([
        "period", "supplier_id", "item_id", "avg_actual_lead_days",
        "avg_predicted_lead_days", "lead_time_error_days", "lead_time_abs_error",
        "lead_time_mape", "sample_count", "p90_actual_lead_days", "on_time_rate",
        "late_delivery_count",
    ])
    _write_mart(con, result, "mart.mart_lead_time_analysis")
    return result


class TestLeadTimeAnalysis:
    """ë¦¬ë“œíƒ€ì„ ë¶„ì„ ë§ˆíŠ¸ í…ŒìŠ¤íŠ¸."""

    def test_lead_time_accuracy(self):
        """ì˜ˆì¸¡ vs ì‹¤ì  ë¦¬ë“œíƒ€ì„ ì •í™•ë„ë¥¼ ê²€ì¦í•œë‹¤."""
        con = duckdb.connect(":memory:")
        _create_lt_tables(con)
        config = {"thresholds": {"constraints": {"supply": {"late_threshold_days": 2}}}}

        # PO ì‹¤ì : ë¦¬ë“œíƒ€ì„ 10ì¼
        con.execute("""
            INSERT INTO core.fact_po (po_id, po_date, supplier_id, item_id)
            VALUES ('PO001', '2024-01-10', 'SUP_A', 'ITEM_A')
        """)
        con.execute("""
            INSERT INTO mart.mart_open_po (po_id, supplier_id, item_id, po_lead_days, eta_vs_actual_days)
            VALUES ('PO001', 'SUP_A', 'ITEM_A', 10.0, 1.0)
        """)

        # ì˜ˆì¸¡: ë¦¬ë“œíƒ€ì„ 12ì¼
        con.execute("""
            INSERT INTO core.fact_lead_time_forecast
                (forecast_id, forecast_date, supplier_id, item_id, predicted_lead_days, forecast_method)
            VALUES ('LTF001', '2024-01-05', 'SUP_A', 'ITEM_A', 12.0, 'HISTORICAL_AVG')
        """)

        result = build_mart_lead_time_analysis_test(con, config)
        assert result.height == 1
        row = result.row(0, named=True)
        assert row["avg_actual_lead_days"] == 10.0
        assert row["avg_predicted_lead_days"] == 12.0
        assert row["lead_time_abs_error"] == 2.0
        # MAPE = 2/10 = 0.2
        assert abs(row["lead_time_mape"] - 0.2) < 1e-3
        # eta_vs_actual=1 <= 2 ì´ë¯€ë¡œ on_time
        assert row["on_time_rate"] == 1.0
        assert row["late_delivery_count"] == 0
        con.close()

    def test_late_delivery_detection(self):
        """ì§€ì—° ë‚©í’ˆì´ ì˜¬ë°”ë¥´ê²Œ ê°ì§€ë˜ëŠ”ì§€ ê²€ì¦í•œë‹¤."""
        con = duckdb.connect(":memory:")
        _create_lt_tables(con)
        config = {"thresholds": {"constraints": {"supply": {"late_threshold_days": 2}}}}

        # PO 2ê±´: 1ê±´ ì •ìƒ(eta_vs_actual=1), 1ê±´ ì§€ì—°(eta_vs_actual=5)
        con.execute("""
            INSERT INTO core.fact_po (po_id, po_date, supplier_id, item_id) VALUES
                ('PO001', '2024-02-10', 'SUP_B', 'ITEM_B'),
                ('PO002', '2024-02-15', 'SUP_B', 'ITEM_B')
        """)
        con.execute("""
            INSERT INTO mart.mart_open_po (po_id, supplier_id, item_id, po_lead_days, eta_vs_actual_days) VALUES
                ('PO001', 'SUP_B', 'ITEM_B', 10.0, 1.0),
                ('PO002', 'SUP_B', 'ITEM_B', 15.0, 5.0)
        """)
        con.execute("""
            INSERT INTO core.fact_lead_time_forecast
                (forecast_id, forecast_date, supplier_id, item_id, predicted_lead_days, forecast_method) VALUES
                ('LTF001', '2024-02-05', 'SUP_B', 'ITEM_B', 11.0, 'ML_MODEL'),
                ('LTF002', '2024-02-10', 'SUP_B', 'ITEM_B', 13.0, 'ML_MODEL')
        """)

        result = build_mart_lead_time_analysis_test(con, config)
        assert result.height == 1
        row = result.row(0, named=True)
        # 2ê±´ ì¤‘ 1ê±´ ì§€ì—°
        assert row["late_delivery_count"] == 1
        assert abs(row["on_time_rate"] - 0.5) < 1e-3
        con.close()

    def test_no_data_no_crash(self):
        """ë°ì´í„° ì—†ì„ ë•Œ ì—ëŸ¬ ì—†ì´ ë¹ˆ ê²°ê³¼ë¥¼ ë°˜í™˜í•œë‹¤."""
        con = duckdb.connect(":memory:")
        _create_lt_tables(con)
        config = {}

        result = build_mart_lead_time_analysis_test(con, config)
        assert result.height == 0
        count = con.execute("SELECT COUNT(*) FROM mart.mart_lead_time_analysis").fetchone()[0]
        assert count == 0
        con.close()
```

---

## ëª¨ë“ˆ 4: ê°€ê²© ìµœì í™” (Price Optimization)

### 4.1 ê°œìš”

- **ëª©ì **: ê°€ê²© ë³€ë™ì— ë”°ë¥¸ ìˆ˜ìš” íƒ„ë ¥ì„± ë¶„ì„, ìµœì  ê°€ê²©ëŒ€ ì œì•ˆ
- **ì…ë ¥**: `core.fact_price_history` (ì‹ ê·œ), `core.fact_shipment`, `mart.mart_pnl_revenue`
- **ì¶œë ¥**: `mart.mart_price_elasticity`
- **ì˜ì¡´ì„±**: ì—†ìŒ (ë…ë¦½)
- **ë‚œì´ë„**: ë³´í†µ | **ì˜ˆìƒ ì†Œìš”**: ~2ì£¼ (ë‹¨ê°€ ì´ë ¥ ìŠ¤í‚¤ë§ˆ ë³€ê²½ í•„ìš”)

**ë°ì´í„° íë¦„**:
```
ì™¸ë¶€ ê°€ê²© ì´ë ¥ â†’ CSV(inbox/) â†’ Ingest â†’ core.fact_price_history
                                                  â”‚
core.fact_shipment (ìˆ˜ìš”ëŸ‰) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                                  â–¼
                                     mart.mart_price_elasticity
```

### 4.2 í˜„ì¬ í•œê³„ ë° ì„ í–‰ ì‘ì—…

í˜„ì¬ `core.fact_settlement` í…Œì´ë¸”ì—ëŠ” `gross_sales`ì™€ `net_payout`ì´ ìˆì§€ë§Œ,
**í’ˆëª©ë³„ ë‹¨ê°€(unit_price)**ëŠ” ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
ê°€ê²© ìµœì í™”ë¥¼ ìœ„í•´ì„œëŠ” í’ˆëª©ë³„ ê°€ê²© ì´ë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.

**ì„ í–‰ ì‘ì—…**:
1. `core.fact_price_history` í…Œì´ë¸” ì‹ ê·œ ìƒì„±
2. ê°€ê²© ë³€ë™ ì´ë ¥ ë°ì´í„° ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ êµ¬ì¶• (ì™¸ë¶€ ERP/POS ì—°ë™ ë˜ëŠ” ìˆ˜ë™ CSV)
3. ìµœì†Œ 3ê°œì›” ì´ìƒì˜ ê°€ê²©/íŒë§¤ ì´ë ¥ ì¶•ì  í›„ íƒ„ë ¥ì„± ë¶„ì„ ì˜ë¯¸ ìˆìŒ

### 4.3 DDL (`src/db.py`ì— ì¶”ê°€)

```python
# ---------- src/db.py  CORE_FACT_TABLES ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€ ----------

    "core.fact_price_history": """
        CREATE TABLE IF NOT EXISTS core.fact_price_history (
            price_id             VARCHAR NOT NULL,
            effective_date       DATE    NOT NULL,
            end_date             DATE,
            item_id              VARCHAR NOT NULL,
            channel_store_id     VARCHAR,
            unit_price           DOUBLE  NOT NULL,
            currency             VARCHAR DEFAULT 'KRW',
            price_type           VARCHAR DEFAULT 'REGULAR',
            discount_pct         DOUBLE  DEFAULT 0.0,
            promotion_id         VARCHAR,
            -- ì‹œìŠ¤í…œ ì»¬ëŸ¼
            source_system        VARCHAR,
            load_batch_id        BIGINT,
            source_file_hash     VARCHAR,
            source_pk            VARCHAR,
            loaded_at            TIMESTAMP DEFAULT current_timestamp
        )
    """,
```

```python
# ---------- src/db.py  MART_TABLES ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€ ----------

    "mart.mart_price_elasticity": """
        CREATE TABLE IF NOT EXISTS mart.mart_price_elasticity (
            item_id              VARCHAR NOT NULL,
            channel_store_id     VARCHAR,
            period               VARCHAR NOT NULL,
            avg_price            DOUBLE,
            prev_avg_price       DOUBLE,
            price_change_pct     DOUBLE,
            avg_daily_qty        DOUBLE,
            prev_avg_daily_qty   DOUBLE,
            qty_change_pct       DOUBLE,
            elasticity           DOUBLE,
            estimated_optimal_price DOUBLE,
            revenue_at_current   DOUBLE,
            revenue_at_optimal   DOUBLE,
            sample_days          INTEGER
        )
    """,
```

### 4.4 ìŠ¤í‚¤ë§ˆ ì„¤ì • (`config/schema.yaml`ì— ì¶”ê°€)

```yaml
# ---------- config/schema.yaml ì— ì¶”ê°€ ----------

fact_price_history:
  description: "í’ˆëª©ë³„ ê°€ê²© ë³€ë™ ì´ë ¥ (ì •ê°€, í• ì¸ê°€, í”„ë¡œëª¨ì…˜ ê°€ê²©)"
  business_key: ["price_id"]
  event_date_column: "effective_date"
  required_columns:
    - {name: "source_system", type: "VARCHAR"}
    - {name: "price_id", type: "VARCHAR"}
    - {name: "effective_date", type: "DATE"}
    - {name: "item_id", type: "VARCHAR"}
    - {name: "unit_price", type: "DOUBLE"}
  optional_columns:
    - {name: "end_date", type: "DATE"}
    - {name: "channel_store_id", type: "VARCHAR"}
    - {name: "currency", type: "VARCHAR"}
    - {name: "price_type", type: "VARCHAR"}
    - {name: "discount_pct", type: "DOUBLE"}
    - {name: "promotion_id", type: "VARCHAR"}
```

### 4.5 ë¹Œë” ì½”ë“œ (`src/mart_price.py` - ì‹ ê·œ íŒŒì¼)

```python
# ---------- src/mart_price.py (ì‹ ê·œ íŒŒì¼) ----------
"""
ê°€ê²© íƒ„ë ¥ì„± ë¶„ì„ ë§ˆíŠ¸ ë¹Œë”.
ê°€ê²© ë³€ë™ê³¼ ìˆ˜ìš” ë³€í™”ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì  ê°€ê²©ëŒ€ë¥¼ ì œì•ˆí•œë‹¤.
íƒ„ë ¥ì„±(elasticity) = %ë³€í™”(ìˆ˜ìš”) / %ë³€í™”(ê°€ê²©)
"""
import logging

import duckdb
import polars as pl

logger = logging.getLogger(__name__)


def _write_mart(con: duckdb.DuckDBPyConnection, df: pl.DataFrame, table: str) -> None:
    """DELETE-INSERT íŒ¨í„´ìœ¼ë¡œ ë§ˆíŠ¸ í…Œì´ë¸”ì— ì ì¬í•œë‹¤."""
    con.execute(f"DELETE FROM {table}")
    if df.height == 0:
        return
    arrow = df.to_arrow()
    staging = f"_stg_{table.replace('.', '_')}"
    con.register(staging, arrow)
    con.execute(f"INSERT INTO {table} SELECT * FROM {staging}")
    con.unregister(staging)


def _safe_query(con: duckdb.DuckDBPyConnection, sql: str) -> pl.DataFrame:
    """ì•ˆì „í•˜ê²Œ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ê³  Polars DataFrameì„ ë°˜í™˜í•œë‹¤."""
    try:
        return con.execute(sql).pl()
    except Exception as e:
        logger.error("Query failed: %s", e)
        return pl.DataFrame()


def build_mart_price_elasticity(
    con: duckdb.DuckDBPyConnection, config: dict
) -> pl.DataFrame:
    """
    ê°€ê²© íƒ„ë ¥ì„± ë§ˆíŠ¸ë¥¼ ìƒì„±í•œë‹¤.
    - ì›”ë³„ í‰ê·  ê°€ê²©ê³¼ í‰ê·  ì¼ë³„ íŒë§¤ëŸ‰ì„ ê³„ì‚°
    - ì „ì›” ëŒ€ë¹„ ê°€ê²©/ìˆ˜ëŸ‰ ë³€í™”ìœ¨ ì‚°ì¶œ
    - íƒ„ë ¥ì„± = %ìˆ˜ëŸ‰ë³€í™” / %ê°€ê²©ë³€í™”
    - ìµœì  ê°€ê²© ì¶”ì •: íƒ„ë ¥ì„±ì´ -1 ê·¼ì²˜ì¸ ì§€ì  (ìˆ˜ìµ ê·¹ëŒ€í™”)
    """
    sql = """
        WITH monthly_price AS (
            -- ì›”ë³„ í‰ê·  ê°€ê²©
            SELECT
                STRFTIME(ph.effective_date, '%Y-%m') AS period,
                ph.item_id,
                ph.channel_store_id,
                AVG(ph.unit_price * (1.0 - COALESCE(ph.discount_pct, 0))) AS avg_price
            FROM core.fact_price_history ph
            GROUP BY 1, 2, 3
        ),
        monthly_demand AS (
            -- ì›”ë³„ ì¼í‰ê·  íŒë§¤ëŸ‰
            SELECT
                STRFTIME(s.ship_date, '%Y-%m') AS period,
                s.item_id,
                s.channel_store_id,
                SUM(s.qty_shipped)::DOUBLE / COUNT(DISTINCT s.ship_date) AS avg_daily_qty,
                COUNT(DISTINCT s.ship_date) AS sample_days
            FROM core.fact_shipment s
            GROUP BY 1, 2, 3
        ),
        combined AS (
            SELECT
                p.period,
                p.item_id,
                p.channel_store_id,
                p.avg_price,
                d.avg_daily_qty,
                d.sample_days,
                LAG(p.avg_price) OVER (
                    PARTITION BY p.item_id, p.channel_store_id ORDER BY p.period
                ) AS prev_avg_price,
                LAG(d.avg_daily_qty) OVER (
                    PARTITION BY p.item_id, p.channel_store_id ORDER BY p.period
                ) AS prev_avg_daily_qty
            FROM monthly_price p
            JOIN monthly_demand d
                ON  p.period = d.period
                AND p.item_id = d.item_id
                AND COALESCE(p.channel_store_id, '__NULL__') = COALESCE(d.channel_store_id, '__NULL__')
        )
        SELECT
            item_id,
            channel_store_id,
            period,
            ROUND(avg_price, 2)           AS avg_price,
            ROUND(prev_avg_price, 2)      AS prev_avg_price,
            CASE
                WHEN prev_avg_price IS NULL OR prev_avg_price = 0 THEN NULL
                ELSE ROUND((avg_price - prev_avg_price) / prev_avg_price, 4)
            END                           AS price_change_pct,
            ROUND(avg_daily_qty, 2)       AS avg_daily_qty,
            ROUND(prev_avg_daily_qty, 2)  AS prev_avg_daily_qty,
            CASE
                WHEN prev_avg_daily_qty IS NULL OR prev_avg_daily_qty = 0 THEN NULL
                ELSE ROUND((avg_daily_qty - prev_avg_daily_qty) / prev_avg_daily_qty, 4)
            END                           AS qty_change_pct,
            -- íƒ„ë ¥ì„± = %ìˆ˜ëŸ‰ë³€í™” / %ê°€ê²©ë³€í™”
            CASE
                WHEN prev_avg_price IS NULL OR prev_avg_price = 0
                  OR prev_avg_daily_qty IS NULL OR prev_avg_daily_qty = 0
                  OR (avg_price - prev_avg_price) = 0 THEN NULL
                ELSE ROUND(
                    ((avg_daily_qty - prev_avg_daily_qty) / prev_avg_daily_qty)
                    / ((avg_price - prev_avg_price) / prev_avg_price),
                    4
                )
            END                           AS elasticity,
            -- ìµœì  ê°€ê²© ì¶”ì •: P_optimal = P_current * (e / (e + 1)) (e < -1 ì¼ ë•Œ)
            CASE
                WHEN prev_avg_price IS NULL OR prev_avg_price = 0
                  OR prev_avg_daily_qty IS NULL OR prev_avg_daily_qty = 0
                  OR (avg_price - prev_avg_price) = 0 THEN NULL
                WHEN ((avg_daily_qty - prev_avg_daily_qty) / prev_avg_daily_qty)
                    / ((avg_price - prev_avg_price) / prev_avg_price) >= -1 THEN NULL
                ELSE ROUND(
                    avg_price * (
                        ((avg_daily_qty - prev_avg_daily_qty) / prev_avg_daily_qty)
                        / ((avg_price - prev_avg_price) / prev_avg_price)
                    ) / (
                        ((avg_daily_qty - prev_avg_daily_qty) / prev_avg_daily_qty)
                        / ((avg_price - prev_avg_price) / prev_avg_price) + 1
                    ), 2
                )
            END                           AS estimated_optimal_price,
            ROUND(avg_price * avg_daily_qty, 2) AS revenue_at_current,
            -- ìµœì  ê°€ê²©ì—ì„œì˜ ì¶”ì • ìˆ˜ìµ
            NULL::DOUBLE                  AS revenue_at_optimal,
            sample_days::INTEGER          AS sample_days
        FROM combined
        WHERE period IS NOT NULL
        ORDER BY item_id, period
    """

    df = _safe_query(con, sql)
    if df.height == 0:
        logger.warning("price_elasticity: ê°€ê²©/íŒë§¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        _write_mart(con, pl.DataFrame(), "mart.mart_price_elasticity")
        return pl.DataFrame()

    # revenue_at_optimal ê³„ì‚° (Polars)
    result = df.with_columns([
        pl.when(pl.col("estimated_optimal_price").is_not_null() & pl.col("elasticity").is_not_null())
          .then(
              # Q_optimal = Q_current * (1 + e * (P_opt - P_cur) / P_cur)
              pl.col("avg_daily_qty") * (
                  1.0 + pl.col("elasticity") * (
                      (pl.col("estimated_optimal_price") - pl.col("avg_price")) / pl.col("avg_price")
                  )
              ) * pl.col("estimated_optimal_price")
          )
          .otherwise(pl.lit(None))
          .round(2)
          .alias("revenue_at_optimal"),
    ]).select([
        "item_id", "channel_store_id", "period",
        "avg_price", "prev_avg_price", "price_change_pct",
        "avg_daily_qty", "prev_avg_daily_qty", "qty_change_pct",
        "elasticity", "estimated_optimal_price",
        "revenue_at_current", "revenue_at_optimal", "sample_days",
    ])

    _write_mart(con, result, "mart.mart_price_elasticity")
    logger.info("mart_price_elasticity: %d rows written", result.height)
    return result


def build_all_price_marts(
    con: duckdb.DuckDBPyConnection, config: dict
) -> None:
    """ê°€ê²© ë¶„ì„ ê´€ë ¨ ëª¨ë“  ë§ˆíŠ¸ë¥¼ ë¹Œë“œí•œë‹¤."""
    logger.info("-- ê°€ê²© ë¶„ì„ ë§ˆíŠ¸ ë¹Œë“œ ì‹œì‘ --")
    build_mart_price_elasticity(con, config)
    logger.info("-- ê°€ê²© ë¶„ì„ ë§ˆíŠ¸ ë¹Œë“œ ì™„ë£Œ --")
```

### 4.6 íŒŒì´í”„ë¼ì¸ ì—°ê²° (`run.py` ìˆ˜ì •)

```python
# ---------- run.py ì„í¬íŠ¸ ì˜ì—­ì— ì¶”ê°€ ----------
from src.mart_price import build_all_price_marts
```

```python
# ---------- run.py  run_pipeline() í•¨ìˆ˜ ë‚´ Phase 2.6 ì´í›„ì— ì¶”ê°€ ----------

        logger.info("=== PHASE 2.6: Lead Time Marts ===")
        build_all_lead_time_marts(con, config)

        # â–¼â–¼â–¼ ì—¬ê¸°ì— ì¶”ê°€ â–¼â–¼â–¼
        logger.info("=== PHASE 2.7: Price Marts ===")
        build_all_price_marts(con, config)
        # â–²â–²â–² ì¶”ê°€ ë â–²â–²â–²

        logger.info("=== PHASE 3: Cost Allocation ===")
```

### 4.7 ëŒ€ì‹œë³´ë“œ íƒ­ (`app/pnl_app.py`ì— ì¶”ê°€)

ê¸°ì¡´ P&L ëŒ€ì‹œë³´ë“œì— "ê°€ê²© ë¶„ì„" íƒ­ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

```python
# ---------- app/pnl_app.py  íƒ­ ì •ì˜ ì˜ì—­ì— "ê°€ê²© ë¶„ì„" ì¶”ê°€ ----------
# ê¸°ì¡´ íƒ­ ëª©ë¡ì— "ê°€ê²© ë¶„ì„" ì¶”ê°€:
# tab_rev, tab_cost, ..., tab_price = st.tabs([..., "ê°€ê²© ë¶„ì„"])

    with tab_price:
        st.subheader("ê°€ê²© íƒ„ë ¥ì„± ë¶„ì„")

        if not _has_table(con, "mart", "mart_price_elasticity"):
            st.warning("mart.mart_price_elasticity í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        else:
            # í’ˆëª© í•„í„°
            items_pe = query_df(con, "SELECT DISTINCT item_id FROM mart.mart_price_elasticity ORDER BY item_id")
            selected_item = st.selectbox(
                "í’ˆëª© ì„ íƒ", ["ì „ì²´"] + (items_pe["item_id"].tolist() if len(items_pe) > 0 else []),
                key="pe_item"
            )
            item_where = "" if selected_item == "ì „ì²´" else f"WHERE item_id = '{selected_item}'"

            # KPI ì¹´ë“œ
            pe_kpi_sql = f"""
                SELECT
                    COUNT(DISTINCT item_id)                  AS item_count,
                    ROUND(AVG(elasticity), 2)                AS avg_elasticity,
                    COUNT(*) FILTER (WHERE elasticity < -1)  AS elastic_count,
                    COUNT(*) FILTER (WHERE elasticity >= -1 AND elasticity < 0)  AS inelastic_count
                FROM mart.mart_price_elasticity
                {item_where}
            """
            pe_kpi = query_df(con, pe_kpi_sql)
            if len(pe_kpi) > 0:
                c1, c2, c3, c4 = st.columns(4)
                c1.metric("ë¶„ì„ í’ˆëª© ìˆ˜", f"{int(pe_kpi.iloc[0]['item_count']):,}")
                c2.metric("í‰ê·  íƒ„ë ¥ì„±", f"{pe_kpi.iloc[0]['avg_elasticity']}")
                c3.metric("íƒ„ë ¥ì  í’ˆëª©", f"{int(pe_kpi.iloc[0]['elastic_count']):,}")
                c4.metric("ë¹„íƒ„ë ¥ì  í’ˆëª©", f"{int(pe_kpi.iloc[0]['inelastic_count']):,}")

            # íƒ„ë ¥ì„± ì¶”ì´ ì°¨íŠ¸
            st.subheader("ì›”ë³„ íƒ„ë ¥ì„± ì¶”ì´")
            pe_trend_sql = f"""
                SELECT period, ROUND(AVG(elasticity), 2) AS avg_elasticity
                FROM mart.mart_price_elasticity
                {item_where}
                GROUP BY period ORDER BY period
            """
            pe_trend = query_df(con, pe_trend_sql)
            if len(pe_trend) > 0:
                st.line_chart(pe_trend.set_index("period"), use_container_width=True)

            # ìµœì  ê°€ê²© ì œì•ˆ í…Œì´ë¸”
            st.subheader("ìµœì  ê°€ê²© ì œì•ˆ")
            optimal_sql = f"""
                SELECT
                    item_id                         AS "í’ˆëª©ì½”ë“œ",
                    period                          AS "ê¸°ê°„",
                    avg_price                       AS "í˜„ì¬ê°€ê²©",
                    ROUND(elasticity, 2)            AS "íƒ„ë ¥ì„±",
                    estimated_optimal_price         AS "ìµœì ê°€ê²©",
                    ROUND(revenue_at_current, 0)    AS "í˜„ì¬ìˆ˜ìµ",
                    ROUND(revenue_at_optimal, 0)    AS "ìµœì ìˆ˜ìµ",
                    CASE
                        WHEN revenue_at_optimal > revenue_at_current
                        THEN ROUND((revenue_at_optimal - revenue_at_current) / NULLIF(revenue_at_current, 0) * 100, 1)
                        ELSE 0
                    END                             AS "ìˆ˜ìµê°œì„ (%)"
                FROM mart.mart_price_elasticity
                {item_where}
                ORDER BY period DESC, item_id
            """
            optimal_df = query_df(con, optimal_sql)
            if len(optimal_df) > 0:
                st.dataframe(optimal_df, use_container_width=True, height=400)
            else:
                st.info("ê°€ê²© íƒ„ë ¥ì„± ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            # ìˆ˜ìµ ì‹œë®¬ë ˆì´ì…˜ (ì„ íƒëœ í’ˆëª©)
            if selected_item != "ì „ì²´":
                st.subheader("ìˆ˜ìµ ì‹œë®¬ë ˆì´ì…˜")
                latest_sql = f"""
                    SELECT avg_price, elasticity, avg_daily_qty
                    FROM mart.mart_price_elasticity
                    WHERE item_id = '{selected_item}' AND elasticity IS NOT NULL
                    ORDER BY period DESC LIMIT 1
                """
                latest = query_df(con, latest_sql)
                if len(latest) > 0:
                    base_price = float(latest.iloc[0]["avg_price"])
                    base_e = float(latest.iloc[0]["elasticity"])
                    base_qty = float(latest.iloc[0]["avg_daily_qty"])

                    price_adj = st.slider(
                        "ê°€ê²© ì¡°ì •ë¥  (%)",
                        min_value=-30, max_value=30, value=0, step=1,
                        key="price_sim_slider"
                    )
                    new_price = base_price * (1 + price_adj / 100.0)
                    new_qty = base_qty * (1 + base_e * price_adj / 100.0)
                    new_qty = max(new_qty, 0)

                    c1, c2, c3 = st.columns(3)
                    c1.metric("ì¡°ì • ê°€ê²©", f"{new_price:,.0f}ì›",
                              delta=f"{price_adj}%")
                    c2.metric("ì˜ˆìƒ ì¼ íŒë§¤ëŸ‰", f"{new_qty:,.1f}",
                              delta=f"{(new_qty/base_qty - 1)*100:.1f}%" if base_qty > 0 else "")
                    c3.metric("ì˜ˆìƒ ì¼ ìˆ˜ìµ", f"{new_price * new_qty:,.0f}ì›",
                              delta=f"{((new_price*new_qty)/(base_price*base_qty)-1)*100:.1f}%" if base_price*base_qty > 0 else "")
                else:
                    st.info("ì„ íƒí•œ í’ˆëª©ì˜ íƒ„ë ¥ì„± ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
```

### 4.8 í…ŒìŠ¤íŠ¸ (`tests/test_price.py` - ì‹ ê·œ íŒŒì¼)

```python
# ---------- tests/test_price.py (ì‹ ê·œ íŒŒì¼) ----------
"""
ê°€ê²© íƒ„ë ¥ì„± ë§ˆíŠ¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸.
"""
import duckdb
import polars as pl
import pytest


def _write_mart(con, df, table):
    con.execute(f"DELETE FROM {table}")
    if df.height == 0:
        return
    arrow = df.to_arrow()
    staging = f"_stg_{table.replace('.', '_')}"
    con.register(staging, arrow)
    con.execute(f"INSERT INTO {table} SELECT * FROM {staging}")
    con.unregister(staging)


def _safe_query(con, sql):
    try:
        return con.execute(sql).pl()
    except Exception:
        return pl.DataFrame()


def _create_price_tables(con):
    """ê°€ê²© í…ŒìŠ¤íŠ¸ìš© í…Œì´ë¸” ìƒì„±."""
    con.execute("CREATE SCHEMA IF NOT EXISTS core")
    con.execute("CREATE SCHEMA IF NOT EXISTS mart")

    con.execute("""
        CREATE TABLE IF NOT EXISTS core.fact_price_history (
            price_id VARCHAR NOT NULL, effective_date DATE NOT NULL,
            end_date DATE, item_id VARCHAR NOT NULL,
            channel_store_id VARCHAR, unit_price DOUBLE NOT NULL,
            currency VARCHAR DEFAULT 'KRW', price_type VARCHAR DEFAULT 'REGULAR',
            discount_pct DOUBLE DEFAULT 0.0, promotion_id VARCHAR,
            source_system VARCHAR, load_batch_id BIGINT,
            source_file_hash VARCHAR, source_pk VARCHAR,
            loaded_at TIMESTAMP DEFAULT current_timestamp
        )
    """)
    con.execute("""
        CREATE TABLE IF NOT EXISTS core.fact_shipment (
            shipment_id VARCHAR NOT NULL, ship_date DATE NOT NULL,
            warehouse_id VARCHAR, item_id VARCHAR NOT NULL,
            qty_shipped DOUBLE NOT NULL, channel_order_id VARCHAR,
            channel_store_id VARCHAR,
            source_system VARCHAR, load_batch_id BIGINT,
            source_file_hash VARCHAR, source_pk VARCHAR,
            loaded_at TIMESTAMP DEFAULT current_timestamp
        )
    """)
    con.execute("""
        CREATE TABLE IF NOT EXISTS mart.mart_price_elasticity (
            item_id VARCHAR NOT NULL, channel_store_id VARCHAR,
            period VARCHAR NOT NULL, avg_price DOUBLE, prev_avg_price DOUBLE,
            price_change_pct DOUBLE, avg_daily_qty DOUBLE,
            prev_avg_daily_qty DOUBLE, qty_change_pct DOUBLE,
            elasticity DOUBLE, estimated_optimal_price DOUBLE,
            revenue_at_current DOUBLE, revenue_at_optimal DOUBLE,
            sample_days INTEGER
        )
    """)


def build_mart_price_elasticity_test(con, config):
    """í…ŒìŠ¤íŠ¸ìš© ì¸ë¼ì¸ ë¹Œë”."""
    sql = """
        WITH monthly_price AS (
            SELECT STRFTIME(ph.effective_date, '%Y-%m') AS period, ph.item_id,
                   ph.channel_store_id,
                   AVG(ph.unit_price * (1.0 - COALESCE(ph.discount_pct, 0))) AS avg_price
            FROM core.fact_price_history ph GROUP BY 1, 2, 3
        ),
        monthly_demand AS (
            SELECT STRFTIME(s.ship_date, '%Y-%m') AS period, s.item_id, s.channel_store_id,
                   SUM(s.qty_shipped)::DOUBLE / COUNT(DISTINCT s.ship_date) AS avg_daily_qty,
                   COUNT(DISTINCT s.ship_date) AS sample_days
            FROM core.fact_shipment s GROUP BY 1, 2, 3
        ),
        combined AS (
            SELECT p.period, p.item_id, p.channel_store_id, p.avg_price, d.avg_daily_qty, d.sample_days,
                   LAG(p.avg_price) OVER (PARTITION BY p.item_id, p.channel_store_id ORDER BY p.period) AS prev_avg_price,
                   LAG(d.avg_daily_qty) OVER (PARTITION BY p.item_id, p.channel_store_id ORDER BY p.period) AS prev_avg_daily_qty
            FROM monthly_price p
            JOIN monthly_demand d ON p.period = d.period AND p.item_id = d.item_id
                AND COALESCE(p.channel_store_id, '__NULL__') = COALESCE(d.channel_store_id, '__NULL__')
        )
        SELECT item_id, channel_store_id, period,
               ROUND(avg_price, 2) AS avg_price,
               ROUND(prev_avg_price, 2) AS prev_avg_price,
               CASE WHEN prev_avg_price IS NULL OR prev_avg_price = 0 THEN NULL
                    ELSE ROUND((avg_price - prev_avg_price) / prev_avg_price, 4) END AS price_change_pct,
               ROUND(avg_daily_qty, 2) AS avg_daily_qty,
               ROUND(prev_avg_daily_qty, 2) AS prev_avg_daily_qty,
               CASE WHEN prev_avg_daily_qty IS NULL OR prev_avg_daily_qty = 0 THEN NULL
                    ELSE ROUND((avg_daily_qty - prev_avg_daily_qty) / prev_avg_daily_qty, 4) END AS qty_change_pct,
               CASE WHEN prev_avg_price IS NULL OR prev_avg_price = 0
                      OR prev_avg_daily_qty IS NULL OR prev_avg_daily_qty = 0
                      OR (avg_price - prev_avg_price) = 0 THEN NULL
                    ELSE ROUND(((avg_daily_qty - prev_avg_daily_qty) / prev_avg_daily_qty)
                         / ((avg_price - prev_avg_price) / prev_avg_price), 4) END AS elasticity,
               NULL::DOUBLE AS estimated_optimal_price,
               ROUND(avg_price * avg_daily_qty, 2) AS revenue_at_current,
               NULL::DOUBLE AS revenue_at_optimal,
               sample_days::INTEGER AS sample_days
        FROM combined WHERE period IS NOT NULL ORDER BY item_id, period
    """
    df = _safe_query(con, sql)
    if df.height == 0:
        _write_mart(con, pl.DataFrame(), "mart.mart_price_elasticity")
        return pl.DataFrame()

    result = df.with_columns([
        pl.when(pl.col("elasticity").is_not_null() & (pl.col("elasticity") < -1.0))
          .then(
              pl.col("avg_price") * pl.col("elasticity") / (pl.col("elasticity") + 1.0)
          )
          .otherwise(pl.lit(None))
          .round(2)
          .alias("estimated_optimal_price"),
    ]).with_columns([
        pl.when(pl.col("estimated_optimal_price").is_not_null() & pl.col("elasticity").is_not_null())
          .then(
              pl.col("avg_daily_qty") * (
                  1.0 + pl.col("elasticity") * (
                      (pl.col("estimated_optimal_price") - pl.col("avg_price")) / pl.col("avg_price")
                  )
              ) * pl.col("estimated_optimal_price")
          )
          .otherwise(pl.lit(None))
          .round(2)
          .alias("revenue_at_optimal"),
    ]).select([
        "item_id", "channel_store_id", "period", "avg_price", "prev_avg_price",
        "price_change_pct", "avg_daily_qty", "prev_avg_daily_qty", "qty_change_pct",
        "elasticity", "estimated_optimal_price", "revenue_at_current",
        "revenue_at_optimal", "sample_days",
    ])
    _write_mart(con, result, "mart.mart_price_elasticity")
    return result


class TestPriceElasticity:
    """ê°€ê²© íƒ„ë ¥ì„± ë§ˆíŠ¸ í…ŒìŠ¤íŠ¸."""

    def test_elasticity_calculation(self):
        """ê°€ê²© 10% ìƒìŠ¹, ìˆ˜ìš” 20% ê°ì†Œ â†’ íƒ„ë ¥ì„± = -2.0 ì„ ê²€ì¦í•œë‹¤."""
        con = duckdb.connect(":memory:")
        _create_price_tables(con)

        # 1ì›”: ê°€ê²© 1000ì›, ì¼ íŒë§¤ 100ê°œ (ì¼ìˆ˜ 10ì¼, ì´ 1000ê°œ)
        for day in range(1, 11):
            d = f"2024-01-{day:02d}"
            con.execute(f"""
                INSERT INTO core.fact_price_history (price_id, effective_date, item_id, unit_price)
                VALUES ('P1_{day}', '{d}', 'ITEM_X', 1000.0)
            """)
            con.execute(f"""
                INSERT INTO core.fact_shipment (shipment_id, ship_date, item_id, qty_shipped)
                VALUES ('S1_{day}', '{d}', 'ITEM_X', 100.0)
            """)

        # 2ì›”: ê°€ê²© 1100ì› (+10%), ì¼ íŒë§¤ 80ê°œ (-20%)
        for day in range(1, 11):
            d = f"2024-02-{day:02d}"
            con.execute(f"""
                INSERT INTO core.fact_price_history (price_id, effective_date, item_id, unit_price)
                VALUES ('P2_{day}', '{d}', 'ITEM_X', 1100.0)
            """)
            con.execute(f"""
                INSERT INTO core.fact_shipment (shipment_id, ship_date, item_id, qty_shipped)
                VALUES ('S2_{day}', '{d}', 'ITEM_X', 80.0)
            """)

        result = build_mart_price_elasticity_test(con, {})

        # 1ì›”ì€ prevê°€ ì—†ìœ¼ë¯€ë¡œ íƒ„ë ¥ì„± NULL, 2ì›”ì— ê³„ì‚°ë¨
        feb = result.filter(pl.col("period") == "2024-02")
        assert feb.height == 1
        row = feb.row(0, named=True)
        # íƒ„ë ¥ì„± = (-20%/+10%) = -2.0
        assert abs(row["elasticity"] - (-2.0)) < 0.01
        con.close()

    def test_no_data_no_crash(self):
        """ë°ì´í„° ì—†ì„ ë•Œ ì—ëŸ¬ ì—†ì´ ë¹ˆ ê²°ê³¼ë¥¼ ë°˜í™˜í•œë‹¤."""
        con = duckdb.connect(":memory:")
        _create_price_tables(con)

        result = build_mart_price_elasticity_test(con, {})
        assert result.height == 0
        con.close()

    def test_optimal_price_only_for_elastic(self):
        """íƒ„ë ¥ì„±ì´ -1 ë¯¸ë§Œ(íƒ„ë ¥ì )ì¸ ê²½ìš°ì—ë§Œ ìµœì  ê°€ê²©ì´ ê³„ì‚°ëœë‹¤."""
        con = duckdb.connect(":memory:")
        _create_price_tables(con)

        # 1ì›”: ê°€ê²© 1000ì›, íŒë§¤ 100
        for day in range(1, 6):
            d = f"2024-01-{day:02d}"
            con.execute(f"""
                INSERT INTO core.fact_price_history (price_id, effective_date, item_id, unit_price)
                VALUES ('P1_{day}', '{d}', 'ITEM_Y', 1000.0)
            """)
            con.execute(f"""
                INSERT INTO core.fact_shipment (shipment_id, ship_date, item_id, qty_shipped)
                VALUES ('S1_{day}', '{d}', 'ITEM_Y', 100.0)
            """)

        # 2ì›”: ê°€ê²© 1100ì› (+10%), íŒë§¤ 95 (-5%) â†’ íƒ„ë ¥ì„± = -0.5 (ë¹„íƒ„ë ¥ì )
        for day in range(1, 6):
            d = f"2024-02-{day:02d}"
            con.execute(f"""
                INSERT INTO core.fact_price_history (price_id, effective_date, item_id, unit_price)
                VALUES ('P2_{day}', '{d}', 'ITEM_Y', 1100.0)
            """)
            con.execute(f"""
                INSERT INTO core.fact_shipment (shipment_id, ship_date, item_id, qty_shipped)
                VALUES ('S2_{day}', '{d}', 'ITEM_Y', 95.0)
            """)

        result = build_mart_price_elasticity_test(con, {})
        feb = result.filter(pl.col("period") == "2024-02")
        assert feb.height == 1
        row = feb.row(0, named=True)
        # íƒ„ë ¥ì„± = (-5%/+10%) = -0.5 â†’ ë¹„íƒ„ë ¥ì  â†’ ìµœì  ê°€ê²© NULL
        assert abs(row["elasticity"] - (-0.5)) < 0.01
        assert row["estimated_optimal_price"] is None
        con.close()
```

---

## ëª¨ë“ˆ 5: ì˜ˆì¸¡ ê±°ë²„ë„ŒìŠ¤ (Forecast Governance)

### 5.1 ê°œìš”

- **ëª©ì **: ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥ ì¶”ì , ëª¨ë¸ ê°„ ë¹„êµ, ìë™ ìµœì  ëª¨ë¸ ì„ íƒ (Champion/Challenger)
- **ì…ë ¥**: `core.dim_forecast_model`, `mart.mart_forecast_accuracy`
- **ì¶œë ¥**: `mart.mart_model_performance`
- **ì˜ì¡´ì„±**: ëª¨ë“ˆ 1 (ìˆ˜ìš” ì˜ˆì¸¡)
- **ë‚œì´ë„**: ì‰¬ì›€ | **ì˜ˆìƒ ì†Œìš”**: ~2ì¼

**ë°ì´í„° íë¦„**:
```
core.dim_forecast_model â”€â”€â”€â”€â”€â”€â”
                              â”œâ”€â”€â–¶ mart.mart_model_performance
mart.mart_forecast_accuracy â”€â”€â”˜
```

### 5.2 DDL (`src/db.py`ì— ì¶”ê°€)

`core.dim_forecast_model`ì€ ëª¨ë“ˆ 1(1.2ì ˆ)ì—ì„œ ì´ë¯¸ ì •ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.

```python
# ---------- src/db.py  MART_TABLES ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€ ----------

    "mart.mart_model_performance": """
        CREATE TABLE IF NOT EXISTS mart.mart_model_performance (
            forecast_method      VARCHAR NOT NULL,
            period               VARCHAR NOT NULL,
            item_count           INTEGER,
            avg_mape             DOUBLE,
            avg_bias             DOUBLE,
            avg_accuracy_pct     DOUBLE,
            median_mape          DOUBLE,
            p90_mape             DOUBLE,
            total_forecast_qty   DOUBLE,
            total_actual_qty     DOUBLE,
            is_champion          BOOLEAN,
            rank_in_period       INTEGER,
            mape_trend           VARCHAR,
            drift_detected       BOOLEAN
        )
    """,
```

### 5.3 ë¹Œë” ì½”ë“œ (`src/mart_forecast.py`ì— ì¶”ê°€)

`src/mart_forecast.py` íŒŒì¼ì˜ `build_all_forecast_marts` í•¨ìˆ˜ ìœ„ì— ë‹¤ìŒ í•¨ìˆ˜ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

```python
# ---------- src/mart_forecast.py ì— í•¨ìˆ˜ ì¶”ê°€ ----------


def build_mart_model_performance(
    con: duckdb.DuckDBPyConnection, config: dict
) -> pl.DataFrame:
    """
    ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë§ˆíŠ¸ë¥¼ ìƒì„±í•œë‹¤.
    - ëª¨ë¸ë³„/ê¸°ê°„ë³„ MAPE, bias, accuracy ì§‘ê³„
    - Champion ëª¨ë¸: í•´ë‹¹ ê¸°ê°„ì—ì„œ avg_mape ê°€ ê°€ì¥ ë‚®ì€ ëª¨ë¸
    - MAPE ì¶”ì´(drift): ì§ì „ ê¸°ê°„ ëŒ€ë¹„ MAPE ê°€ 50% ì´ìƒ ì•…í™” ì‹œ drift ê°ì§€
    """
    fc_policy = config.get("forecast_policy", {})
    mape_critical = fc_policy.get("thresholds", {}).get("mape_critical", 0.40)

    sql = """
        WITH perf AS (
            SELECT
                forecast_method,
                period,
                COUNT(DISTINCT item_id)   AS item_count,
                AVG(mape)                 AS avg_mape,
                AVG(bias)                 AS avg_bias,
                AVG(accuracy_pct)         AS avg_accuracy_pct,
                PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY mape) AS median_mape,
                PERCENTILE_CONT(0.9) WITHIN GROUP (ORDER BY mape) AS p90_mape,
                SUM(forecast_qty)         AS total_forecast_qty,
                SUM(actual_qty)           AS total_actual_qty
            FROM mart.mart_forecast_accuracy
            WHERE forecast_method IS NOT NULL
            GROUP BY forecast_method, period
        ),
        ranked AS (
            SELECT
                *,
                RANK() OVER (PARTITION BY period ORDER BY avg_mape ASC) AS rank_in_period,
                LAG(avg_mape) OVER (PARTITION BY forecast_method ORDER BY period) AS prev_mape
            FROM perf
        )
        SELECT
            forecast_method,
            period,
            item_count::INTEGER          AS item_count,
            ROUND(avg_mape, 4)           AS avg_mape,
            ROUND(avg_bias, 4)           AS avg_bias,
            ROUND(avg_accuracy_pct, 4)   AS avg_accuracy_pct,
            ROUND(median_mape, 4)        AS median_mape,
            ROUND(p90_mape, 4)           AS p90_mape,
            ROUND(total_forecast_qty, 0) AS total_forecast_qty,
            ROUND(total_actual_qty, 0)   AS total_actual_qty,
            (rank_in_period = 1)         AS is_champion,
            rank_in_period::INTEGER      AS rank_in_period,
            CASE
                WHEN prev_mape IS NULL THEN 'N/A'
                WHEN avg_mape < prev_mape THEN 'IMPROVING'
                WHEN avg_mape > prev_mape * 1.1 THEN 'DEGRADING'
                ELSE 'STABLE'
            END                          AS mape_trend,
            CASE
                WHEN prev_mape IS NOT NULL AND avg_mape > prev_mape * 1.5 THEN true
                ELSE false
            END                          AS drift_detected
        FROM ranked
        ORDER BY period, rank_in_period
    """

    df = _safe_query(con, sql)
    if df.height == 0:
        logger.warning("model_performance: ì˜ˆì¸¡ ì •í™•ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        _write_mart(con, pl.DataFrame(), "mart.mart_model_performance")
        return pl.DataFrame()

    result = df.select([
        "forecast_method", "period", "item_count",
        "avg_mape", "avg_bias", "avg_accuracy_pct",
        "median_mape", "p90_mape",
        "total_forecast_qty", "total_actual_qty",
        "is_champion", "rank_in_period", "mape_trend", "drift_detected",
    ])

    _write_mart(con, result, "mart.mart_model_performance")
    logger.info("mart_model_performance: %d rows written", result.height)

    # ë“œë¦¬í”„íŠ¸ ê²½ê³ 
    drift_rows = result.filter(pl.col("drift_detected") == True)
    if drift_rows.height > 0:
        for row in drift_rows.iter_rows(named=True):
            logger.warning(
                "DRIFT DETECTED: ëª¨ë¸ '%s' ê¸°ê°„ '%s' â€” MAPE ê¸‰ë“± ê°ì§€",
                row["forecast_method"], row["period"],
            )

    return result
```

ê·¸ë¦¬ê³  `build_all_forecast_marts` í•¨ìˆ˜ë¥¼ ìµœì¢… ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤:

```python
# ---------- build_all_forecast_marts ìµœì¢… ìˆ˜ì • ----------

def build_all_forecast_marts(
    con: duckdb.DuckDBPyConnection, config: dict
) -> None:
    """ìˆ˜ìš” ì˜ˆì¸¡, ë³´ì¶© ë°œì£¼, ëª¨ë¸ ì„±ëŠ¥ ê´€ë ¨ ëª¨ë“  ë§ˆíŠ¸ë¥¼ ë¹Œë“œí•œë‹¤."""
    logger.info("-- ìˆ˜ìš” ì˜ˆì¸¡ ë§ˆíŠ¸ ë¹Œë“œ ì‹œì‘ --")
    build_mart_forecast_accuracy(con, config)
    build_mart_demand_plan(con, config)
    build_mart_replenishment_plan(con, config)
    build_mart_model_performance(con, config)
    logger.info("-- ìˆ˜ìš” ì˜ˆì¸¡ ë§ˆíŠ¸ ë¹Œë“œ ì™„ë£Œ --")
```

### 5.4 ëŒ€ì‹œë³´ë“œ íƒ­ (`app/forecast_app.py`ì— ì¶”ê°€)

ê¸°ì¡´ `app/forecast_app.py`ì˜ íƒ­ ëª©ë¡ì— "ëª¨ë¸ ë¹„êµ" íƒ­ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

```python
# ---------- app/forecast_app.py  íƒ­ ì •ì˜ ìˆ˜ì • ----------
# ê¸°ì¡´: tab0, tab1, tab2 = st.tabs(["ì˜ˆì¸¡ vs ì‹¤ì ", "ì •í™•ë„ ì¶”ì´", "ìˆ˜ìš” ê³„íš"])
# ë³€ê²½:
    tab0, tab1, tab2, tab3 = st.tabs(["ì˜ˆì¸¡ vs ì‹¤ì ", "ì •í™•ë„ ì¶”ì´", "ìˆ˜ìš” ê³„íš", "ëª¨ë¸ ë¹„êµ"])

    # â”€â”€ Tab 3: ëª¨ë¸ ë¹„êµ (ê±°ë²„ë„ŒìŠ¤) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with tab3:
        st.subheader("ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")

        if not _has_table(con, "mart", "mart_model_performance"):
            st.warning("mart.mart_model_performance í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # Champion ëª¨ë¸ í‘œì‹œ
            champion_sql = """
                SELECT forecast_method, period,
                       ROUND(avg_mape * 100, 1) AS mape_pct,
                       ROUND(avg_accuracy_pct * 100, 1) AS accuracy_pct
                FROM mart.mart_model_performance
                WHERE is_champion = true
                ORDER BY period DESC
                LIMIT 1
            """
            champ = query_df(con, champion_sql)
            if len(champ) > 0:
                st.success(
                    f"í˜„ì¬ Champion ëª¨ë¸: **{champ.iloc[0]['forecast_method']}** "
                    f"(MAPE {champ.iloc[0]['mape_pct']}%, "
                    f"ì •í™•ë„ {champ.iloc[0]['accuracy_pct']}%, "
                    f"ê¸°ê°„ {champ.iloc[0]['period']})"
                )

            # ë“œë¦¬í”„íŠ¸ ì•Œë¦¼
            drift_sql = """
                SELECT forecast_method, period, ROUND(avg_mape * 100, 1) AS mape_pct
                FROM mart.mart_model_performance
                WHERE drift_detected = true
                ORDER BY period DESC
            """
            drift_df = query_df(con, drift_sql)
            if len(drift_df) > 0:
                for _, row in drift_df.iterrows():
                    st.error(
                        f"DRIFT ê°ì§€: ëª¨ë¸ '{row['forecast_method']}' "
                        f"ê¸°ê°„ {row['period']} â€” MAPE {row['mape_pct']}%"
                    )

            # ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸”
            st.subheader("ê¸°ê°„ë³„ ëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„")
            perf_sql = """
                SELECT
                    period                               AS "ê¸°ê°„",
                    forecast_method                      AS "ì˜ˆì¸¡ë°©ë²•",
                    rank_in_period                       AS "ìˆœìœ„",
                    ROUND(avg_mape * 100, 1)             AS "MAPE(%)",
                    ROUND(avg_bias * 100, 1)             AS "Bias(%)",
                    ROUND(avg_accuracy_pct * 100, 1)     AS "ì •í™•ë„(%)",
                    item_count                           AS "í’ˆëª©ìˆ˜",
                    CASE WHEN is_champion THEN 'Champion' ELSE '' END AS "ìƒíƒœ",
                    mape_trend                           AS "ì¶”ì´",
                    CASE WHEN drift_detected THEN 'DRIFT' ELSE '' END AS "ê²½ê³ "
                FROM mart.mart_model_performance
                ORDER BY period DESC, rank_in_period
            """
            perf_df = query_df(con, perf_sql)
            if len(perf_df) > 0:
                st.dataframe(perf_df, use_container_width=True, height=400)

            # ëª¨ë¸ë³„ MAPE ì¶”ì´ ì°¨íŠ¸
            st.subheader("ëª¨ë¸ë³„ MAPE ì¶”ì´")
            trend_sql = """
                SELECT period, forecast_method,
                       ROUND(avg_mape * 100, 1) AS mape_pct
                FROM mart.mart_model_performance
                ORDER BY period
            """
            trend_df = query_df(con, trend_sql)
            if len(trend_df) > 0:
                pivoted = trend_df.pivot_table(
                    index="period", columns="forecast_method", values="mape_pct"
                )
                st.line_chart(pivoted, use_container_width=True)

            # Champion ì´ë ¥
            st.subheader("Champion ëª¨ë¸ ì´ë ¥")
            champ_hist_sql = """
                SELECT period AS "ê¸°ê°„", forecast_method AS "Champion ëª¨ë¸",
                       ROUND(avg_mape * 100, 1) AS "MAPE(%)"
                FROM mart.mart_model_performance
                WHERE is_champion = true
                ORDER BY period
            """
            champ_hist = query_df(con, champ_hist_sql)
            if len(champ_hist) > 0:
                st.dataframe(champ_hist, use_container_width=True)
```

### 5.5 í…ŒìŠ¤íŠ¸ (`tests/test_forecast.py`ì— ì¶”ê°€)

```python
# ---------- tests/test_forecast.py ì— ì¶”ê°€ ----------


def _create_governance_tables(con):
    """ê±°ë²„ë„ŒìŠ¤ í…ŒìŠ¤íŠ¸ìš© ì¶”ê°€ í…Œì´ë¸” ìƒì„±."""
    _create_tables(con)
    con.execute("""
        CREATE TABLE IF NOT EXISTS mart.mart_model_performance (
            forecast_method VARCHAR NOT NULL, period VARCHAR NOT NULL,
            item_count INTEGER, avg_mape DOUBLE, avg_bias DOUBLE,
            avg_accuracy_pct DOUBLE, median_mape DOUBLE, p90_mape DOUBLE,
            total_forecast_qty DOUBLE, total_actual_qty DOUBLE,
            is_champion BOOLEAN, rank_in_period INTEGER,
            mape_trend VARCHAR, drift_detected BOOLEAN
        )
    """)


def build_mart_model_performance_test(con, config):
    """í…ŒìŠ¤íŠ¸ìš© ëª¨ë¸ ì„±ëŠ¥ ë¹Œë” (ì¸ë¼ì¸)."""
    sql = """
        WITH perf AS (
            SELECT forecast_method, period,
                   COUNT(DISTINCT item_id) AS item_count,
                   AVG(mape) AS avg_mape, AVG(bias) AS avg_bias,
                   AVG(accuracy_pct) AS avg_accuracy_pct,
                   PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY mape) AS median_mape,
                   PERCENTILE_CONT(0.9) WITHIN GROUP (ORDER BY mape) AS p90_mape,
                   SUM(forecast_qty) AS total_forecast_qty,
                   SUM(actual_qty) AS total_actual_qty
            FROM mart.mart_forecast_accuracy
            WHERE forecast_method IS NOT NULL
            GROUP BY forecast_method, period
        ),
        ranked AS (
            SELECT *,
                   RANK() OVER (PARTITION BY period ORDER BY avg_mape ASC) AS rank_in_period,
                   LAG(avg_mape) OVER (PARTITION BY forecast_method ORDER BY period) AS prev_mape
            FROM perf
        )
        SELECT forecast_method, period,
               item_count::INTEGER AS item_count,
               ROUND(avg_mape, 4) AS avg_mape,
               ROUND(avg_bias, 4) AS avg_bias,
               ROUND(avg_accuracy_pct, 4) AS avg_accuracy_pct,
               ROUND(median_mape, 4) AS median_mape,
               ROUND(p90_mape, 4) AS p90_mape,
               ROUND(total_forecast_qty, 0) AS total_forecast_qty,
               ROUND(total_actual_qty, 0) AS total_actual_qty,
               (rank_in_period = 1) AS is_champion,
               rank_in_period::INTEGER AS rank_in_period,
               CASE WHEN prev_mape IS NULL THEN 'N/A'
                    WHEN avg_mape < prev_mape THEN 'IMPROVING'
                    WHEN avg_mape > prev_mape * 1.1 THEN 'DEGRADING'
                    ELSE 'STABLE' END AS mape_trend,
               CASE WHEN prev_mape IS NOT NULL AND avg_mape > prev_mape * 1.5 THEN true
                    ELSE false END AS drift_detected
        FROM ranked ORDER BY period, rank_in_period
    """
    df = _safe_query(con, sql)
    if df.height == 0:
        _write_mart(con, pl.DataFrame(), "mart.mart_model_performance")
        return pl.DataFrame()
    result = df.select([
        "forecast_method", "period", "item_count",
        "avg_mape", "avg_bias", "avg_accuracy_pct",
        "median_mape", "p90_mape", "total_forecast_qty", "total_actual_qty",
        "is_champion", "rank_in_period", "mape_trend", "drift_detected",
    ])
    _write_mart(con, result, "mart.mart_model_performance")
    return result


class TestModelPerformance:
    """ëª¨ë¸ ì„±ëŠ¥(ê±°ë²„ë„ŒìŠ¤) ë§ˆíŠ¸ í…ŒìŠ¤íŠ¸."""

    def test_champion_selection(self):
        """MAPEê°€ ë‚®ì€ ëª¨ë¸ì´ champion ìœ¼ë¡œ ì„ íƒë˜ëŠ”ì§€ ê²€ì¦í•œë‹¤."""
        con = duckdb.connect(":memory:")
        _create_governance_tables(con)

        # ì •í™•ë„ ë§ˆíŠ¸ì— 2ê°œ ëª¨ë¸ ë°ì´í„° ì§ì ‘ ì‚½ì…
        con.execute("""
            INSERT INTO mart.mart_forecast_accuracy
                (period, item_id, warehouse_id, forecast_method,
                 actual_qty, forecast_qty, error_qty, abs_error, mape, bias, accuracy_pct)
            VALUES
                ('2024-01', 'ITEM_A', 'WH1', 'PROPHET', 100, 110, 10, 10, 0.10, 0.10, 0.90),
                ('2024-01', 'ITEM_A', 'WH1', 'NAIVE_AVG', 100, 130, 30, 30, 0.30, 0.30, 0.70)
        """)

        result = build_mart_model_performance_test(con, {})
        assert result.height == 2

        prophet = result.filter(pl.col("forecast_method") == "PROPHET")
        naive = result.filter(pl.col("forecast_method") == "NAIVE_AVG")

        # PROPHET(MAPE=0.10)ì´ champion
        assert prophet.row(0, named=True)["is_champion"] == True
        assert prophet.row(0, named=True)["rank_in_period"] == 1
        assert naive.row(0, named=True)["is_champion"] == False
        assert naive.row(0, named=True)["rank_in_period"] == 2
        con.close()

    def test_drift_detection(self):
        """MAPEê°€ ì „ê¸° ëŒ€ë¹„ 50% ì´ìƒ ì•…í™”ë˜ë©´ driftê°€ ê°ì§€ë˜ëŠ”ì§€ ê²€ì¦í•œë‹¤."""
        con = duckdb.connect(":memory:")
        _create_governance_tables(con)

        # 1ì›”: MAPE=0.10
        con.execute("""
            INSERT INTO mart.mart_forecast_accuracy
                (period, item_id, warehouse_id, forecast_method,
                 actual_qty, forecast_qty, error_qty, abs_error, mape, bias, accuracy_pct)
            VALUES ('2024-01', 'ITEM_A', 'WH1', 'PROPHET', 100, 110, 10, 10, 0.10, 0.10, 0.90)
        """)

        # 2ì›”: MAPE=0.40 (0.10ì˜ 4ë°° â†’ 50% ì´ìƒ ì•…í™”)
        con.execute("""
            INSERT INTO mart.mart_forecast_accuracy
                (period, item_id, warehouse_id, forecast_method,
                 actual_qty, forecast_qty, error_qty, abs_error, mape, bias, accuracy_pct)
            VALUES ('2024-02', 'ITEM_A', 'WH1', 'PROPHET', 100, 140, 40, 40, 0.40, 0.40, 0.60)
        """)

        result = build_mart_model_performance_test(con, {})

        feb = result.filter(pl.col("period") == "2024-02")
        assert feb.height == 1
        row = feb.row(0, named=True)
        assert row["drift_detected"] == True
        assert row["mape_trend"] == "DEGRADING"
        con.close()
```

---

## ë¶€ë¡: ì‹¤í–‰ ê°€ì´ë“œ

### A. ëª¨ë“ˆ ì ìš© ìˆœì„œ (ê¶Œì¥)

```
ë‹¨ê³„ 1 â”€â”€â”€ ëª¨ë“ˆ 1 (ìˆ˜ìš” ì˜ˆì¸¡)     â† ê¸°ë°˜ ëª¨ë“ˆ, ìµœìš°ì„ 
ë‹¨ê³„ 2 â”€â”¬â”€ ëª¨ë“ˆ 3 (ë¦¬ë“œíƒ€ì„)      â† ë…ë¦½, ë³‘ë ¬ ê°€ëŠ¥
        â””â”€ ëª¨ë“ˆ 5 (ê±°ë²„ë„ŒìŠ¤)       â† ëª¨ë“ˆ 1 ì™„ë£Œ í›„ ì¦‰ì‹œ
ë‹¨ê³„ 3 â”€â”€â”€ ëª¨ë“ˆ 2 (ë³´ì¶© ë°œì£¼)     â† ëª¨ë“ˆ 1 í•„ìš” (ì—†ìœ¼ë©´ fallback)
ë‹¨ê³„ 4 â”€â”€â”€ ëª¨ë“ˆ 4 (ê°€ê²© ìµœì í™”)   â† ìŠ¤í‚¤ë§ˆ ë³€ê²½ í•„ìš”, ë§ˆì§€ë§‰
```

**ë³‘ë ¬ ì‘ì—… ê°€ëŠ¥ ì¡°í•©**:
- ëª¨ë“ˆ 1 + ëª¨ë“ˆ 3 (ì„œë¡œ ë…ë¦½)
- ëª¨ë“ˆ 1 + ëª¨ë“ˆ 4 (ì„œë¡œ ë…ë¦½)
- ëª¨ë“ˆ 3 + ëª¨ë“ˆ 4 (ì„œë¡œ ë…ë¦½)

### B. ê° ëª¨ë“ˆ ì ìš© ì²´í¬ë¦¬ìŠ¤íŠ¸

ëª¨ë“  ëª¨ë“ˆì— ê³µí†µìœ¼ë¡œ ì ìš©ë˜ëŠ” ì²´í¬ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.

```
[ ] 1. src/db.py ì— DDL ì¶”ê°€ (CORE_FACT_TABLES, MART_TABLES)
[ ] 2. config/schema.yaml ì— ìŠ¤í‚¤ë§ˆ ì •ì˜ ì¶”ê°€
[ ] 3. config/ í•˜ìœ„ ì •ì±… YAML íŒŒì¼ ìƒì„±/ìˆ˜ì •
[ ] 4. ë¹Œë” ì½”ë“œ íŒŒì¼ ìƒì„±/ìˆ˜ì • (src/mart_*.py)
[ ] 5. run.py ì— Phase ì¶”ê°€ (ì„í¬íŠ¸ + í˜¸ì¶œ)
[ ] 6. í…Œì´ë¸” ì´ˆê¸°í™”: python run.py --init
[ ] 7. íŒŒì´í”„ë¼ì¸ 1íšŒ ì‹¤í–‰: python run.py --once
[ ] 8. ëŒ€ì‹œë³´ë“œ íŒŒì¼ ìƒì„±/ìˆ˜ì • (app/*_app.py)
[ ] 9. config/column_aliases.yaml ì— ë³„ì¹­ ì¶”ê°€
[ ] 10. config/policies/coverage_policy.yaml ì— ë„ë©”ì¸ ì¶”ê°€
[ ] 11. í…ŒìŠ¤íŠ¸ ì‹¤í–‰: pytest tests/ -v
[ ] 12. ëŒ€ì‹œë³´ë“œ í™•ì¸: streamlit run app/<name>_app.py
```

### C. ëª¨ë“ˆë³„ íŒŒì¼ ë³€ê²½ ëª©ë¡

| íŒŒì¼ | ëª¨ë“ˆ1 | ëª¨ë“ˆ2 | ëª¨ë“ˆ3 | ëª¨ë“ˆ4 | ëª¨ë“ˆ5 |
|------|-------|-------|-------|-------|-------|
| `src/db.py` | ìˆ˜ì • | ìˆ˜ì • | ìˆ˜ì • | ìˆ˜ì • | ìˆ˜ì • |
| `src/mart_forecast.py` | **ìƒì„±** | ìˆ˜ì • | - | - | ìˆ˜ì • |
| `src/mart_lead_time.py` | - | - | **ìƒì„±** | - | - |
| `src/mart_price.py` | - | - | - | **ìƒì„±** | - |
| `run.py` | ìˆ˜ì • | - | ìˆ˜ì • | ìˆ˜ì • | - |
| `config/schema.yaml` | ìˆ˜ì • | - | ìˆ˜ì • | ìˆ˜ì • | - |
| `config/column_aliases.yaml` | ìˆ˜ì • | - | - | - | - |
| `config/policies/forecast_policy.yaml` | **ìƒì„±** | - | - | - | - |
| `config/policies/coverage_policy.yaml` | ìˆ˜ì • | - | - | - | - |
| `config/thresholds.yaml` | - | ìˆ˜ì • | - | - | - |
| `app/forecast_app.py` | **ìƒì„±** | - | - | - | ìˆ˜ì • |
| `app/scm_app.py` | - | ìˆ˜ì • | ìˆ˜ì • | - | - |
| `app/pnl_app.py` | - | - | - | ìˆ˜ì • | - |
| `tests/test_forecast.py` | **ìƒì„±** | ìˆ˜ì • | - | - | ìˆ˜ì • |
| `tests/test_lead_time.py` | - | - | **ìƒì„±** | - | - |
| `tests/test_price.py` | - | - | - | **ìƒì„±** | - |

### D. ì™¸ë¶€ ì˜ˆì¸¡ ëª¨ë¸ ì—°ë™ ë°©ë²•

ì˜ˆì¸¡ ëª¨ë¸ì€ íŒŒì´í”„ë¼ì¸ **ì™¸ë¶€**ì—ì„œ ì‹¤í–‰ë˜ë©°, ê²°ê³¼ë§Œ CSV/XLSX í˜•íƒœë¡œ ì ì¬í•©ë‹ˆë‹¤.
ì´ ì„¤ê³„ëŠ” ëª¨ë¸ í•™ìŠµ í™˜ê²½(GPU ì„œë²„, í´ë¼ìš°ë“œ ë“±)ê³¼ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ë¶„ë¦¬í•©ë‹ˆë‹¤.

**ì—°ë™ í”„ë¡œì„¸ìŠ¤**:

```
[ì™¸ë¶€ í™˜ê²½]                          [íŒŒì´í”„ë¼ì¸]

1. ëª¨ë¸ í•™ìŠµ
   (Prophet/ARIMA/XGBoost)
          â”‚
2. ì˜ˆì¸¡ ê²°ê³¼ CSV ìƒì„±
   - demand_forecast_YYYYMMDD.csv
   - lead_time_forecast_YYYYMMDD.csv
          â”‚
3. inbox/ ë””ë ‰í„°ë¦¬ì— íŒŒì¼ ë³µì‚¬  â”€â”€â–¶  4. Ingest Phase ì—ì„œ ìë™ ê°ì§€
                                         â”‚
                                     5. core.fact_demand_forecast ì— ì ì¬
                                         â”‚
                                     6. Phase 2.5 ì—ì„œ ë§ˆíŠ¸ ë¹Œë“œ
                                         â”‚
                                     7. ëŒ€ì‹œë³´ë“œì—ì„œ ê²°ê³¼ í™•ì¸
```

**CSV í¬ë§· ì˜ˆì‹œ** (`demand_forecast_YYYYMMDD.csv`):

```csv
forecast_id,forecast_date,target_date,item_id,warehouse_id,channel_store_id,forecast_qty,forecast_method,model_version,lower_bound,upper_bound,confidence_level
FC-20240101-001,2024-01-01,2024-01-15,ITEM_A,WH1,,120.5,PROPHET,v2.1,95.2,145.8,0.95
FC-20240101-002,2024-01-01,2024-01-15,ITEM_A,WH2,,85.3,PROPHET,v2.1,68.2,102.4,0.95
FC-20240101-003,2024-01-01,2024-01-16,ITEM_A,WH1,,118.0,PROPHET,v2.1,93.4,142.6,0.95
```

**CSV í¬ë§· ì˜ˆì‹œ** (`lead_time_forecast_YYYYMMDD.csv`):

```csv
forecast_id,forecast_date,supplier_id,item_id,origin_country,dest_warehouse_id,predicted_lead_days,lower_bound_days,upper_bound_days,confidence_level,forecast_method
LTF-20240101-001,2024-01-01,SUP_A,ITEM_A,CN,WH1,12.5,10.0,15.0,0.95,HISTORICAL_AVG
LTF-20240101-002,2024-01-01,SUP_B,,KR,WH1,3.0,2.0,4.0,0.95,HISTORICAL_AVG
```

**ìë™í™” íŒ**:
- cron/ìŠ¤ì¼€ì¤„ëŸ¬ë¡œ ëª¨ë¸ í•™ìŠµ â†’ CSV ìƒì„± â†’ inbox/ ë³µì‚¬ë¥¼ ìë™í™”
- `source_system` ì»¬ëŸ¼ì— ëª¨ë¸ ì‹¤í–‰ í™˜ê²½ ì •ë³´ë¥¼ ê¸°ë¡ (ì˜ˆ: "prophet_gpu_server_01")
- `model_version` ì»¬ëŸ¼ìœ¼ë¡œ ëª¨ë¸ ë²„ì „ì„ ì¶”ì í•˜ì—¬ ê±°ë²„ë„ŒìŠ¤(ëª¨ë“ˆ5)ì— í™œìš©

### E. run.py ìµœì¢… Phase êµ¬ì„±

ëª¨ë“  ëª¨ë“ˆ ì ìš© í›„ `run.py`ì˜ ìµœì¢… Phase êµ¬ì„±:

```python
def run_pipeline(con, config, dry_run=False):
    batch_id = acquire_lock(con)
    try:
        logger.info("=== PHASE 1: Ingestion ===")
        results = ingest_all(con, config, batch_id=batch_id, dry_run=dry_run)

        logger.info("=== PHASE 2: SCM Marts ===")
        build_all_scm_marts(con, config)

        logger.info("=== PHASE 2.5: Forecast Marts ===")
        build_all_forecast_marts(con, config)
        # ë‚´ë¶€: forecast_accuracy â†’ demand_plan â†’ replenishment â†’ model_performance

        logger.info("=== PHASE 2.6: Lead Time Marts ===")
        build_all_lead_time_marts(con, config)

        logger.info("=== PHASE 2.7: Price Marts ===")
        build_all_price_marts(con, config)

        logger.info("=== PHASE 3: Cost Allocation ===")
        allocate_all_charges(con, config)

        logger.info("=== PHASE 4: P&L Marts ===")
        build_all_pnl_marts(con, config)

        logger.info("=== PHASE 5: Reconciliation ===")
        run_reconciliation(con, config)

        logger.info("=== PHASE 6: Constraints ===")
        detect_constraints(con, config)

        logger.info("=== PHASE 7: Coverage ===")
        compute_coverage(con, config)

        release_lock(con, batch_id, status="success")
    except Exception as e:
        release_lock(con, batch_id, status="failed", error=str(e))
        raise
```

### F. ëŒ€ì‹œë³´ë“œ ì‹¤í–‰ í¬íŠ¸ ì •ë¦¬

| ëŒ€ì‹œë³´ë“œ | íŒŒì¼ | í¬íŠ¸ | ì‹¤í–‰ ëª…ë ¹ |
|---------|------|------|----------|
| SCM ìš´ì˜ | `app/scm_app.py` | 8501 | `streamlit run app/scm_app.py --server.port 8501` |
| P&L ì†ìµ | `app/pnl_app.py` | 8502 | `streamlit run app/pnl_app.py --server.port 8502` |
| ìˆ˜ìš” ì˜ˆì¸¡ | `app/forecast_app.py` | 8503 | `streamlit run app/forecast_app.py --server.port 8503` |

### G. ìƒˆ í…Œì´ë¸” ì „ì²´ ëª©ë¡

| ìŠ¤í‚¤ë§ˆ | í…Œì´ë¸” | ìœ í˜• | ë„ì… ëª¨ë“ˆ |
|--------|--------|------|----------|
| core | fact_demand_forecast | Fact | ëª¨ë“ˆ 1 |
| core | dim_forecast_model | Dimension | ëª¨ë“ˆ 1 |
| core | fact_lead_time_forecast | Fact | ëª¨ë“ˆ 3 |
| core | fact_price_history | Fact | ëª¨ë“ˆ 4 |
| mart | mart_forecast_accuracy | Mart | ëª¨ë“ˆ 1 |
| mart | mart_demand_plan | Mart | ëª¨ë“ˆ 1 |
| mart | mart_replenishment_plan | Mart | ëª¨ë“ˆ 2 |
| mart | mart_lead_time_analysis | Mart | ëª¨ë“ˆ 3 |
| mart | mart_price_elasticity | Mart | ëª¨ë“ˆ 4 |
| mart | mart_model_performance | Mart | ëª¨ë“ˆ 5 |

**í•©ê³„**: Fact í…Œì´ë¸” 3ê°œ + Dimension 1ê°œ + Mart í…Œì´ë¸” 6ê°œ = **ì´ 10ê°œ ì‹ ê·œ í…Œì´ë¸”**

---

> **ë¬¸ì„œ ë** | ì‘ì„±ì¼: 2026-02-16 | ëŒ€ìƒ ì‹œìŠ¤í…œ: SCM ìš´ì˜ ë¶„ì„ í”Œë«í¼ (DuckDB + Polars + Streamlit)
